{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort and convert ultrasound recordings\n",
    "## General Informations about data structure\n",
    "Clarius Output:\n",
    "- one DICOM-File per recording\n",
    "    - first scanner: 0_0, 0_1, ... (should be C3)\n",
    "    - second scanner: 1_0, 1_1, ... (should be L15)\n",
    "- tar-Files:\n",
    "    - somehow, when you change the scanner in an examination, the Clarius-App doubles all tar-files \n",
    "    - original files: 0_0, 0_1, 0_2, ... (beware numbering is maintained even when the scanner is changed, therefore differs from the numbering of the DICOM files)\n",
    "    - doubled files: 1_0, 1_1, 1_2, ...\n",
    "    - content of Tar files:\n",
    "        - env.raw.lzo   -> lzop-compressed envelope data \n",
    "        - env.tgc       -> meta-informations about time gaine compensation in envelope\n",
    "        - env.yml       -> meta-informations about envelope data\n",
    "        - rf.raw.lzo    -> lzop-compressed rf-data \n",
    "        - (rf.tgc)      -> not in every recording\n",
    "                        -> meta-informations about time gaine compensation in rf-data\n",
    "                        -> also in yaml-files -> differences?\n",
    "        - rf.yml        -> meta-informations about rf-data\n",
    "\n",
    "## Data flow:\n",
    "\n",
    "### Overview\n",
    "1. Hand copy the data into specific folders\n",
    "2. tar files and LZO files are unopacked\n",
    "3. Generate a new Folder for each measurement with extracted RF(as numpy), YAML (as YAML), TGC (as txt), DICOM (as Numpy) in  choosen end_directory for each measurement; \n",
    "4. Rename files according to used transducer and checking the files in comparison with the YAML, creates a list of suspicious files\n",
    "5. Pseudonymise the files according to local ID\n",
    "6. Substract the TGC and split into 2 Files: _no_TGC for files where TGC has been removed and second version where TGC is still contained\n",
    "\n",
    "### 1. Selection of files under investigation\n",
    "- at first saved in a folder \"Patientenaufnahmen/Elastographieaufnahmen_\" + date_oflast recording included  \n",
    "- to work on files, they have to be copied into a folder named \"Testdata\" (working on all files at onced might take very much time, because in the pipeline all files in the directory *Testdata* are processed)\n",
    "\n",
    "### 2.1 Tar-files unpacking:\n",
    "\n",
    "\n",
    "### 2.1 Lzo decompression:\n",
    "\n",
    "### 3. Data conversion and transfer:\n",
    "- create new folder for every recording in *end_directory* (*finished_data*) where converted data is safed\n",
    "- load, change and safe rf.yaml-files (yaml-files need to be changed because Clarius uses wrong character combinations)\n",
    "- extract data arrays out of rf- and DICOM-files and safe them as numpy-arrays\n",
    "    - rf-array[scan_lines, pixel_depth, frames]\n",
    "\n",
    "### 4. Renaming files and checking for Errors:\n",
    "- rename files according to the numbering Clarius gave them\n",
    "    - when there are mistakes in the order of recordings, the files will get wrong names\n",
    "- checking if there are any mistakes in the namings by checking the informations given in the yaml-file\n",
    "- giving out a list of recordings with mistakes -> they have to be checked and either changed or sorted out by hand\n",
    "    - recordings recordings with unsolvable errors are saved in *recordings_with_mistakes*\n",
    "\n",
    "### 5. Pseudonymise recordings:\n",
    "- rename directories based on the encoding in *Users/jakobschaefer/Library/CloudStorage/OneDrive-PersoÌˆnlich/HybridEcho/Forschung/Erfassung_Ultraschalluntersuchungen.xlsx* (Fallnummer -> RedCap-ID)\n",
    "\n",
    "\n",
    "### 6. Cleansing the the time gain compensation from the signals\n",
    "- TGC-Information in .tgc-file, if no .tgc-file exists the tgc given in the yaml-files under \"tgc\" is used\n",
    "- safe changed files under ...rf_no_tgc.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.fft as ff\n",
    "import sys\n",
    "sys.path.insert(0, '..')  # necessary to import functions from other directory\n",
    "import functions.definitions as definitions\n",
    "import yaml # install module called PyYAML\n",
    "import shutil\n",
    "import openpyxl\n",
    "from scipy.signal import hilbert\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy.signal import get_window\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose start_directory and end_directory (conains unsorted ultrasound data) and end_directory (directory where sorted and converted data should be stored)\n",
    "# choose if you want to process all recordings or only new ones\n",
    "process_recordings = 'new' # 'all' or 'new' \n",
    "# if you choose new, you have to copy the files by hand from Elastographieaufnahmenen to Testdata\n",
    "version = 'Vortraining_Tim'\n",
    "\n",
    "if process_recordings == 'all':\n",
    "    start_directory = \"/Volumes/Extreme_SSD/Patientenaufnahmen/Elastographieaufnahmenen_\"+version # directory with data as Clarius outputs it \n",
    "    # copy data into new_directory to process it without changing the original data\n",
    "    new_directory = \"/Volumes/Extreme_SSD/Patientenaufnahmen/Testdata\"\n",
    "    # check if directory exists and create it if not\n",
    "    if not os.path.exists(new_directory):\n",
    "        os.makedirs(new_directory)\n",
    "    # if you want to process all recordings check if directory is empty and copy data if it is\n",
    "    if not os.listdir(new_directory):\n",
    "        shutil.copytree(start_directory, new_directory)\n",
    "\n",
    "# define directory with copied data as new start_directory\n",
    "start_directory = \"/Volumes/Extreme_SSD/Patientenaufnahmen/Testdata\"\n",
    "end_directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data_'+version\n",
    "\n",
    "# if end_directory does not exist, create it\n",
    "if not os.path.exists(end_directory):\n",
    "    os.makedirs(end_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove directories and files starting with '._'\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "\n",
    "for dir in os.listdir(start_directory):\n",
    "    if dir.startswith('.'):\n",
    "        try:\n",
    "            os.rmdir(start_directory + '/' + dir)\n",
    "            print('removed ' + dir)\n",
    "        except:\n",
    "            print('Could not remove directory: ' + dir)\n",
    "        \n",
    "    else:\n",
    "        for file in os.listdir(start_directory+'/'+dir):\n",
    "            if file.startswith('._'):\n",
    "                try:\n",
    "                    os.remove(start_directory + '/' + dir + '/' + file)\n",
    "                    print('removed ' + file)\n",
    "                except:\n",
    "                    print('Could not remove file: ' + file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7267ec00b300451ca610396c6ec38cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unpack all tar-files in the start_directory\n",
    "\n",
    "for root, dirs, files in tqdm(os.walk(start_directory)):\n",
    "    for name in files:\n",
    "        try:\n",
    "            if name.startswith('._'):\n",
    "                os.remove(os.path.join(root, name))\n",
    "                \n",
    "            if name.endswith('.tar') and not name.startswith('._'):\n",
    "                tar = tarfile.open(os.path.join(root, name))\n",
    "                tar.extractall(path = root+'/'+name[:-4])\n",
    "                tar.close()\n",
    "                os.remove(os.path.join(root, name)) \n",
    "        except:\n",
    "            print('Error in: ', os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1861408ab14e5ab1ce496498a775cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decompress all lzo-files in the start_directory\n",
    "\n",
    "for root, dirs, files in tqdm(os.walk(start_directory)):  \n",
    "    for name in files:\n",
    "        if name.endswith(('rf.raw.lzo','env.raw.lzo')):\n",
    "            name_length = len(name)\n",
    "            file_path = os.path.join(root, name)\n",
    "            os.system('lzop -d {}'.format(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efef7f132a143dbbaf11816fb6c626a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 56 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 28 raw frames of size, 192 x 2912 (lines x samples)\n",
      "Loaded 58 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 25 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 32 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 57 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 11 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 15 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 14 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 14 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 61 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 34 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 60 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 60 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 58 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 32 raw frames of size, 192 x 2912 (lines x samples)\n",
      "Loaded 59 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 32 raw frames of size, 192 x 2912 (lines x samples)\n",
      "Loaded 57 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 11 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 16 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 14 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 60 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 61 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 34 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 58 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 11 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 14 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 15 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 60 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 61 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 34 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 59 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 56 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 32 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 61 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 32 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 55 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 14 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 9 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 64 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 36 raw frames of size, 184 x 2544 (lines x samples)\n",
      "Loaded 66 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 37 raw frames of size, 184 x 2544 (lines x samples)\n",
      "Loaded 35 raw frames of size, 184 x 2544 (lines x samples)\n",
      "Loaded 62 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 14 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 10 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 70 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 62 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 34 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 34 raw frames of size, 192 x 2928 (lines x samples)\n",
      "Loaded 39 raw frames of size, 192 x 2128 (lines x samples)\n",
      "Loaded 36 raw frames of size, 192 x 2432 (lines x samples)\n",
      "Loaded 68 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 65 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 39 raw frames of size, 168 x 2432 (lines x samples)\n",
      "Loaded 68 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 14 raw frames of size, 176 x 2688 (lines x samples)\n",
      "Loaded 14 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 10 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 10 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 58 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 33 raw frames of size, 192 x 2608 (lines x samples)\n",
      "Loaded 64 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 38 raw frames of size, 192 x 2400 (lines x samples)\n",
      "Loaded 38 raw frames of size, 192 x 2352 (lines x samples)\n",
      "Loaded 67 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 63 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 34 raw frames of size, 192 x 2576 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 11 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 176 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 34 raw frames of size, 192 x 2704 (lines x samples)\n",
      "Loaded 2 raw frames of size, 192 x 2704 (lines x samples)\n",
      "Loaded 65 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 35 raw frames of size, 192 x 2704 (lines x samples)\n",
      "Loaded 64 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 37 raw frames of size, 144 x 2704 (lines x samples)\n",
      "Loaded 61 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 15 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 13 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2512 (lines x samples)\n",
      "Loaded 12 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 12 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 68 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 40 raw frames of size, 176 x 2256 (lines x samples)\n",
      "Loaded 69 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 43 raw frames of size, 192 x 2032 (lines x samples)\n",
      "Loaded 39 raw frames of size, 160 x 2512 (lines x samples)\n",
      "Loaded 65 raw frames of size, 24 x 304 (lines x samples)\n",
      "Loaded 14 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 168 x 2560 (lines x samples)\n",
      "Loaded 15 raw frames of size, 24 x 208 (lines x samples)\n",
      "Loaded 13 raw frames of size, 192 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 176 x 2736 (lines x samples)\n",
      "Loaded 11 raw frames of size, 24 x 208 (lines x samples)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data into arrays and safe them in extra directory\n",
    "for patient in tqdm(os.listdir(start_directory)):\n",
    "    \n",
    "    # remove doubled files\n",
    "    # somehow the Clarius-App duobles all tar-files when you change the scanner in a examination\n",
    "    # original files are named \"raw_0_X\" and doubled files are named \"raw_1_X\", with X=number of recording\n",
    "    if os.path.isdir(start_directory+\"/\"+patient):\n",
    "        for sub_dir in os.listdir(start_directory+\"/\"+patient):  \n",
    "            if sub_dir.startswith(('raw_1')):\n",
    "                if os.path.isdir(start_directory+\"/\"+patient+\"/\"+sub_dir):\n",
    "                    shutil.rmtree(start_directory+\"/\"+patient+\"/\"+sub_dir) \n",
    "\n",
    "    #create sub-end_directory for every patient\n",
    "    if not os.path.exists(end_directory+\"/\"+patient):\n",
    "            os.mkdir(end_directory+\"/\"+patient)\n",
    "            \n",
    "    # check if there allready files in goal directory\n",
    "    if os.path.isdir(end_directory+\"/\"+patient):\n",
    "        if len(os.listdir(end_directory+\"/\"+patient)) == 0:  \n",
    "            for recording in os.listdir(start_directory+\"/\"+patient):\n",
    "\n",
    "                # Search DICOMs, extract b-mode-array and save it. \n",
    "                if recording.endswith(('.dcm')):\n",
    "                    # define pathof the changed files in the end_directory\n",
    "                    end_path = end_directory+\"/\"+patient+\"/\"+recording   \n",
    "\n",
    "                    file = start_directory+\"/\"+patient+\"/\"+recording\n",
    "                    dcm_array, dcm_array_and_meta = definitions.read_DICOM(file)\n",
    "                    dcm_time = int(dcm_array_and_meta.ContentTime[:6])-int(dcm_array_and_meta.TimezoneOffsetFromUTC[1:])*100 \n",
    "                    dcm_time_and_array = [dcm_time, dcm_array]\n",
    "                    np.save(os.path.dirname(end_path)+\"/\"+recording,dcm_time_and_array)\n",
    "\n",
    "                if os.path.isdir(start_directory+\"/\"+patient+\"/\"+recording):  \n",
    "                    # define end path of the changed files in the end_directory\n",
    "                    end_path = end_directory+\"/\"+patient+\"/\"+recording\n",
    "\n",
    "                    for file in os.listdir(start_directory+\"/\"+patient+\"/\"+recording):\n",
    "                        file_path = start_directory+\"/\"+patient+\"/\"+recording+\"/\"+file\n",
    "\n",
    "                        # search yaml-file, load it, change it and safe it in new directory\n",
    "                        if file.endswith('rf.yml'):\n",
    "                            loaded_yaml = definitions.change_and_load_yaml_pipeline(file_path, end_path)\n",
    "                            sampling_rate = int(loaded_yaml['sampling rate'][:-4])*1e6 #Hz\n",
    "                            imaging_depth = float(loaded_yaml['imaging depth'][:-3]) #mm\n",
    "                            if 'vsound'  in loaded_yaml:\n",
    "                                soundspeed = int(loaded_yaml['vsound'][:-4]) #m/s\n",
    "                            else:\n",
    "                                soundspeed = 1450 #m/s\n",
    "                        \n",
    "                        if file.endswith('rf.raw'):\n",
    "                            rf_data = definitions.load_rf_image(file_path) #numframes -> number of frames to display\n",
    "                            np.save(end_path+\".rf\", rf_data)  \n",
    "\n",
    "                        if file.endswith(('env.tgc','env.tgc.yml')):\n",
    "                            shutil.copy(file_path,end_path+\".rf.tgc\")\n",
    "\n",
    "os.system('say \"Konvertierung der Daten abgeschlossen\"')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedfd1f9866f4e70bc05b457ad73efe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not rename rf-file for T4.2\n",
      "Could not rename rf-file for T4.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename files according to the roi-size and used scanner\n",
    "for dir in tqdm(os.listdir(end_directory)):\n",
    "    C3_large_yaml_files_with_same_name = 0\n",
    "    C3_small_yaml_files_with_same_name = 0\n",
    "    C3_medium_yaml_files_with_same_name = 0\n",
    "    L15_large_yaml_files_with_same_name = 0\n",
    "    L15_small_yaml_files_with_same_name = 0\n",
    "    L15_medium_yaml_files_with_same_name = 0\n",
    "    for file in os.listdir(end_directory+\"/\"+dir):\n",
    "        if file.endswith(\".yaml\") and file.startswith(\"raw\"):\n",
    "            yaml_file = end_directory+\"/\"+dir+\"/\"+file\n",
    "            with open(yaml_file, 'r') as stream:\n",
    "                loaded_yaml = yaml.safe_load(stream)\n",
    "            sampling_rate = int(loaded_yaml['sampling rate'][:-4])*1e6 #Hz\n",
    "            imaging_depth = float(loaded_yaml['imaging depth'][:-3]) #mm\n",
    "            delay_samples = int(loaded_yaml['delay samples'])\n",
    "            number_of_lines = dict(loaded_yaml['size'])['number of lines'] #number of scan-lines horizontal\n",
    "            samples_per_line = dict(loaded_yaml['size'])['samples per line'] #number of samples in one line\n",
    "            iso_time_date = str(loaded_yaml['iso time/date'])\n",
    "\n",
    "            if sampling_rate == 15e6:\n",
    "                scanner = \"C3\"\n",
    "            else: \n",
    "                scanner = \"L15\"\n",
    "            \n",
    "            if number_of_lines > 185:\n",
    "                size = \"large\"\n",
    "            elif number_of_lines == 24:\n",
    "                size = \"small\"\n",
    "            else:\n",
    "                size = \"medium\"\n",
    "            \n",
    "            # check if there allready is a file with same recording modalities\n",
    "            if os.path.isfile(end_directory+\"/\"+dir+\"/C3_\"+size+\".rf.yaml\"):\n",
    "                if size == \"large\":\n",
    "                    C3_large_yaml_files_with_same_name += 1\n",
    "                elif size == \"small\":\n",
    "                    C3_small_yaml_files_with_same_name += 1\n",
    "                elif size == \"medium\":\n",
    "                    C3_medium_yaml_files_with_same_name += 1\n",
    "            \n",
    "            if os.path.isfile(end_directory+\"/\"+dir+\"/L15_\"+size+\".rf.yaml\"):\n",
    "                if size == \"large\":\n",
    "                    L15_large_yaml_files_with_same_name += 1\n",
    "                elif size == \"small\":\n",
    "                    L15_small_yaml_files_with_same_name += 1\n",
    "                elif size == \"medium\":\n",
    "                    L15_medium_yaml_files_with_same_name += 1\n",
    "            \n",
    "\n",
    "            # rename yaml-file\n",
    "            if scanner == \"C3\":\n",
    "                if C3_large_yaml_files_with_same_name > 0:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\"_\"+str(C3_large_yaml_files_with_same_name)+\".rf.yaml\"\n",
    "                elif C3_small_yaml_files_with_same_name > 0:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\"_\"+str(C3_small_yaml_files_with_same_name)+\".rf.yaml\"\n",
    "                elif C3_medium_yaml_files_with_same_name > 0:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\"_\"+str(C3_medium_yaml_files_with_same_name)+\".rf.yaml\"\n",
    "                else:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\".rf.yaml\"\n",
    "            elif scanner == \"L15\":\n",
    "                if L15_large_yaml_files_with_same_name > 0:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\"_\"+str(L15_large_yaml_files_with_same_name)+\".rf.yaml\"\n",
    "                elif L15_small_yaml_files_with_same_name > 0:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\"_\"+str(L15_small_yaml_files_with_same_name)+\".rf.yaml\"\n",
    "                elif L15_medium_yaml_files_with_same_name > 0:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\"_\"+str(L15_medium_yaml_files_with_same_name)+\".rf.yaml\"\n",
    "                else:\n",
    "                    new_yaml_name = end_directory+\"/\"+dir+\"/\"+scanner+\"_\"+size+\".rf.yaml\"\n",
    "\n",
    "            os.rename(yaml_file,new_yaml_name)\n",
    "\n",
    "            # rename according rf- and dcm-files\n",
    "            recognition = file[:7]\n",
    "\n",
    "            # rename rf-file\n",
    "            try:\n",
    "                os.rename(end_directory+\"/\"+dir+\"/\"+recognition+\".rf.npy\",new_yaml_name[:-5]+\".npy\")\n",
    "            except:\n",
    "                print('Could not rename rf-file for '+dir)\n",
    "            \n",
    "            #rename tgc-file\n",
    "            try:\n",
    "                os.rename(end_directory+\"/\"+dir+\"/\"+recognition+\".rf.tgc\",new_yaml_name[:-5]+\".tgc\")\n",
    "            except:\n",
    "                if os.path.isfile(end_directory+\"/\"+dir+\"/\"+recognition+\".rf.tgc\"):\n",
    "                    print('ERROR: Could not rename tgc-file for '+dir) # just if the file exists but there is an other error -> often there is no tgc-file (if autogain was off during recording)          \n",
    "\n",
    "            # rename dcm-file\n",
    "            for dcm_file in os.listdir(end_directory+\"/\"+dir):\n",
    "                if dcm_file.endswith(\".dcm.npy\"):\n",
    "                    # load dcm data\n",
    "                    dcm_data = np.load(end_directory+\"/\"+dir+\"/\"+dcm_file, allow_pickle=True)\n",
    "                    # compare dcm-time and yaml-time\n",
    "                    dcm_time = dcm_data[0]\n",
    "                    yaml_time = int(iso_time_date[11:13]+iso_time_date[14:16]+iso_time_date[17:19])\n",
    "\n",
    "                    if np.abs(dcm_time-yaml_time) <= 2:\n",
    "                        os.rename(end_directory+\"/\"+dir+\"/\"+dcm_file,new_yaml_name[:-8]+\".dcm.npy\")\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "    # remove dcm-files without corresponding yaml-file\n",
    "    for file in os.listdir(end_directory+\"/\"+dir):\n",
    "        if file.startswith(\"1_\") or file.startswith(\"0_\"):\n",
    "            os.remove(end_directory+\"/\"+dir+\"/\"+file)\n",
    "    \n",
    "    # remove tgc-files without corresponding yaml-file\n",
    "    for file in os.listdir(end_directory+\"/\"+dir):\n",
    "        if file.startswith('raw'):\n",
    "            os.remove(end_directory+\"/\"+dir+\"/\"+file)\n",
    "\n",
    "os.system('say \"Umbenennung der Dateien abgeschlossen\"')       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudomise recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudonymise data\n",
    "# in '/Users/jakobschaefer/Library/CloudStorage/OneDrive-PersoÌˆnlich/HybridEcho/Forschung/Erfassung_Ultraschalluntersuchungen.xlsx' is table with encoding of 'Fallnummer'(i.e. Patient-ID) to 'RedCap-ID'\n",
    "# create list ('ID_encoding') with RedCap-ID and Fallnummer\n",
    "\n",
    "\n",
    "directory = end_directory #directory with recordings that need to be peosonymised\n",
    "\n",
    "\n",
    "excel_ultraschalluntersuchungen = openpyxl.load_workbook(r'/Users/jakobschaefer/Library/CloudStorage/OneDrive-PersoÌˆnlich/HybridEcho/Forschung/Erfassung_Ultraschalluntersuchungen.xlsx')\n",
    "\n",
    "ws = excel_ultraschalluntersuchungen['Fibroscan']\n",
    "\n",
    "# create list ('ID_encoding') with RedCap-ID and Fallnummer\n",
    "ID_encoding = [[],[]]\n",
    "for row in range(6, ws.max_row):\n",
    "    cell_RedCap_ID = 'B'+str(row)\n",
    "    ID_encoding[0].append(ws[cell_RedCap_ID].value)\n",
    "    #print(ws[cell].value)\n",
    "    cell_Fallnummer = 'D'+str(row)\n",
    "    ID_encoding[1].append(str(ws[cell_Fallnummer].value))\n",
    "\n",
    "# rename files \n",
    "for dir in os.listdir(directory):\n",
    "\n",
    "    if '.DS_Store' not in dir:\n",
    "        if not dir.startswith('UKD'):\n",
    "            if dir.startswith('.'):\n",
    "                try:\n",
    "                    os.rmdir(directory+'/'+dir)\n",
    "                    print('File' + dir+' started with \"._\" and was removed.')\n",
    "                except:\n",
    "                    print('ERROR: File starts with \"._\": '+dir+ ' And could not be deleted.')\n",
    "\n",
    "            try:\n",
    "                position = ID_encoding[1].index(dir)\n",
    "                os.rename(directory+\"/\"+dir,directory+\"/\"+ID_encoding[0][position])\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following patients have wrong recording modalities: []\n",
      "The following patients have wrong recording modalities in the large recordings: []\n"
     ]
    }
   ],
   "source": [
    "# check if all recordings in Finished_data are fibroscan recordings and if they all have 4 different recording modalities\n",
    "directory_to_check = end_directory\n",
    "#directory_to_check = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data_230607'\n",
    "\n",
    "list_wrong_recordings = []\n",
    "list_wrong_large_recordings = []\n",
    "for dir in os.listdir(directory_to_check):\n",
    "    if dir.startswith('UKD'):\n",
    "        if not dir in ID_encoding[0]:\n",
    "            print('ERROR: '+dir+' is not a fibroscan recording.')\n",
    "\n",
    "    for file in os.listdir(directory_to_check+\"/\"+dir):\n",
    "        if file.endswith('rf.yaml'):\n",
    "            if not file in [\"C3_large.rf.yaml\", \"C3_small.rf.yaml\", \"L15_large.rf.yaml\", \"L15_small.rf.yaml\"]:\n",
    "                list_wrong_recordings.append(dir)\n",
    "            if file in [\"C3_large_1.rf.yaml\", \"L15_large_1.rf.yaml\", \"C3_large_2.rf.yaml\", \"L15_large_2.rf.yaml\"]:\n",
    "                list_wrong_large_recordings.append(dir)\n",
    "\n",
    "list_wrong_recordings = list(dict.fromkeys(list_wrong_recordings))\n",
    "list_wrong_large_recordings = list(dict.fromkeys(list_wrong_large_recordings))\n",
    "\n",
    "print('The following patients have wrong recording modalities: '+str(list_wrong_recordings))\n",
    "print('The following patients have wrong recording modalities in the large recordings: '+str(list_wrong_large_recordings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in /Volumes/Extreme_SSD/Patientenaufnahmen/Testdata were deleted.\n"
     ]
    }
   ],
   "source": [
    "# if there are no more wrong recordings, the files in start_directory can be deleted\n",
    "shutil.rmtree(start_directory)\n",
    "print('All files in '+start_directory+' were deleted.')\n",
    "\n",
    "os.makedirs(start_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleansing the signal from the TGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a669a4a3d74dc6b6ff3fc9995ef775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3-Files where Autogain was OFF: 0 of 67 C3-Files total\n",
      "L15-Files where Autogain was OFF: 0 of 64 L15-Files total\n",
      "Recordings with more rf-frames than tgc-frames: ['T1/C3_small', 'T1/C3_small_2', 'T8/C3_small_1', 'T7/C3_small_1', 'T6/C3_small_2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleansing of the signal from the tgc (for recordings with auto gain ON and OFF)\n",
    "\n",
    "directory = end_directory\n",
    "\n",
    "# count how many recordings without tgc-file (=autogain OFF) are in the directory and which transducer had no tgc-file\n",
    "count_autogain_off_C3 = 0\n",
    "count_autogain_off_L15 = 0\n",
    "count_all_C3 = 0\n",
    "count_all_L15 = 0\n",
    "recordings_with_more_rf_frames_than_tgc_frames = []\n",
    "\n",
    "for dir in tqdm(os.listdir(directory)):\n",
    "    if os.path.isdir(directory+'/'+dir):\n",
    "        for file in  os.listdir(directory+'/'+dir):\n",
    "            # try to remove files that start with \"._\"\n",
    "            if file.startswith(\"._\"):\n",
    "                try:\n",
    "                    os.remove(directory+'/'+dir+'/'+file)\n",
    "                    print('File ' + dir+'/'+file+' started with \"._\" and was removed.')\n",
    "                except:\n",
    "                    print('ERROR: File starts with \"._\": '+dir+'/'+file+ 'And could not be deleted.')\n",
    "                    \n",
    "            if file.endswith('rf.npy') and not os.path.isfile(directory+'/'+dir+'/'+file[:-4]+'_no_tgc.npy'):\n",
    "\n",
    "                # get meta-information out of yaml and calculate pixel_per_millimeter\n",
    "                yaml_file = directory+'/'+dir+'/'+file[:-3]+'yaml'\n",
    "                with open(yaml_file, 'r') as stream:\n",
    "                    yaml_file = yaml.safe_load(stream)  \n",
    "                sampling_rate = float(yaml_file['sampling rate'][:-4])*1e6 # Hz\n",
    "                imaging_depth = float(yaml_file['imaging depth'][:-3])\n",
    "                if 'delay samples' in yaml_file: \n",
    "                    delay_samples = int(yaml_file['delay samples'])\n",
    "                else: \n",
    "                    delay_samples = 0\n",
    "\n",
    "                # clarius made a mistake in their program and calculated with 1540m/s even in 'breast' recordings (where the soundspeed should be 1450m/s)\n",
    "                # therefore 1540m/s is used for all recordings \n",
    "                # PROBLEM: they will change it back eventually -> so I inserted a workaround, where when the results dont fit, the soundspeed is changed to 1450m/s\n",
    "                # calculate number of pixels with the given soundspeed\n",
    "                px_number_1540 = (2*sampling_rate)/(1540*1e3)*imaging_depth\n",
    "                px_number_1450 = (2*sampling_rate)/(1450*1e3)*imaging_depth\n",
    "                actual_px_number = (yaml_file['size']['samples per line'])\n",
    "\n",
    "                if abs(px_number_1540-actual_px_number) > abs(px_number_1450-actual_px_number):\n",
    "                    soundspeed = 1450\n",
    "                elif abs(px_number_1540-actual_px_number) < abs(px_number_1450-actual_px_number):\n",
    "                    soundspeed = 1540\n",
    "\n",
    "                # calculate px/mm \n",
    "                px_per_mm = (2*sampling_rate)/(soundspeed*1e3)\n",
    "\n",
    "                # define which array to change\n",
    "                array = np.load(directory+\"/\"+dir+'/'+file[:-3]+'npy').astype(float)\n",
    "                # if there are delay samples: change the array, so it gets changed at the right places\n",
    "                #if delay_samples>0:\n",
    "                #    delay_array = np.zeros((len(array[:,0,0]),delay_samples,len(array[0,0,:]))) # array, with zeros in front of normal array\n",
    "                #    array = np.append(delay_array, array, axis=1)\n",
    "                    #back_array = 1\n",
    "\n",
    "\n",
    "                # define where to get tgc-values\n",
    "                try: \n",
    "                    tgc = open(directory+'/'+dir+'/'+file[:-3]+'tgc','r')\n",
    "                    lines = tgc.readlines()\n",
    "                    tgc.close()\n",
    "                    number_of_lines = len(array[0,0,:])\n",
    "                    # check if the file has old or new tgc-sorting\n",
    "                    if len(lines)-4 == len(array[0,0,:]): #old sorting\n",
    "                        tgc_sorting = 0\n",
    "                    else: # new sorting\n",
    "                        tgc_sorting = 1\n",
    "\n",
    "                    tgc_option = 'autogain_on' # depending if the auto gain was on or off, the tgc-values are stored in different ways\n",
    "                \n",
    "                except:\n",
    "                    lines = yaml_file['tgc']\n",
    "                    try: \n",
    "                        lines = [item[:-2] for item in lines]\n",
    "                    except: # clarius changed the way they store the tgc-values in the yaml-file\n",
    "                        lines_list = [list(item.keys()) for item in lines]\n",
    "                        flat_lines_list = [item for sublist in lines_list for item in sublist]\n",
    "                        lines = [item[:-2] for item in flat_lines_list]\n",
    "\n",
    "                    tgc_mm = lines[::2]\n",
    "                    tgc_db = lines[1::2]\n",
    "\n",
    "                    tgc_option = 'autogain_off' # depending if the auto gain was on or off, the tgc-values are stored in different ways\n",
    "\n",
    "                    if 'C3' in file:\n",
    "                        count_autogain_off_C3 += 1\n",
    "                    elif 'L15' in file:\n",
    "                        count_autogain_off_L15 += 1\n",
    "\n",
    "\n",
    "                # define array to store new array without tgc\n",
    "                if tgc_option == 'autogain_on':\n",
    "\n",
    "                    # take the tgc-values from one line out of the tgc-file and store it in 'matches'\n",
    "                    # do this for every line in the tgc-file \n",
    "                    # one line in the tgc represents one frame in the matching array  \n",
    "                    array_without_tgc = []\n",
    "                    frame_number = 0\n",
    "                    for i in range(number_of_lines):\n",
    "                        #define new_array (recalculated array will be safed here) bzw. set it back to 0\n",
    "                        new_array = {}\n",
    "\n",
    "                        if tgc_sorting == 0:\n",
    "                            line = lines[i+4]\n",
    "                            tgc_values = re.findall('[\\d,\\.]*(?=mm)|[\\d,\\.]*(?=dB)', line)[::2] # irgendnen scheiss, den Edgar sich Ã¼berlegt hat (Reg Ex heiÃŸt die Methode-> regular expression)\n",
    "                            # matches => List with alternating range (in cm) and matching amplification (in db) \n",
    "                        elif tgc_sorting == 1:\n",
    "                            lines_with_timestamp =[]\n",
    "                            for j,line in enumerate(lines):\n",
    "                                if 'timestamp' in line:\n",
    "                                    lines_with_timestamp.append(j)\n",
    "                            \n",
    "                            if i > len(lines_with_timestamp)-1:\n",
    "                                recordings_with_more_rf_frames_than_tgc_frames.append(dir+'/'+file[:-7])\n",
    "                                break\n",
    "\n",
    "                            nr_tgc_info_that_timestamp = 1\n",
    "                            try: \n",
    "                                while not 'timestamp' in lines[lines_with_timestamp[i]+nr_tgc_info_that_timestamp]: \n",
    "                                    nr_tgc_info_that_timestamp += 1\n",
    "                                nr_tgc_info_that_timestamp -= 1 \n",
    "\n",
    "                                line = str(lines[lines_with_timestamp[i]:lines_with_timestamp[i]+nr_tgc_info_that_timestamp+1])\n",
    "                            except: \n",
    "                                line = str(lines[lines_with_timestamp[i]:len(lines)])\n",
    "\n",
    "                            \n",
    "                            tgc_values = re.findall('[\\d,\\.]*(?=mm)|[\\d,\\.]*(?=dB)', line)[::2]\n",
    "                            # tgc_values => List with pairs of numbers (range in mm and matching amplification in dB)\n",
    "                        else: print('ERROR:'+dir+'/'+file)\n",
    "                        tgc_mm = tgc_values[::2] # range in mm\n",
    "                        tgc_db = tgc_values[1::2] # amplification in dB\n",
    "\n",
    "                        frame_number = i\n",
    "\n",
    "                        # create new array with amplification values (new_amplification_values = 10^(tgc-values/20))\n",
    "                        new_amplification_values = []\n",
    "                        step_list = [] # list with the number of pixels for each amplification step \n",
    "                        nr_px_already_included = 0\n",
    "                        start_amplification = 0\n",
    "                        for number_tgc_values in range(0,len(tgc_mm)):\n",
    "                            length_amplification_step = int(np.round(float(tgc_mm[number_tgc_values])*px_per_mm)-nr_px_already_included)\n",
    "                            amplification_range = np.linspace(start_amplification,float(tgc_db[number_tgc_values]), length_amplification_step) # amplification in dB over the range in px\n",
    "                            new_amplification_values.append(10**(amplification_range/20)) # amplification in linear values over the range in px\n",
    "                            start_amplification = float(tgc_db[number_tgc_values])\n",
    "                            nr_px_already_included += length_amplification_step\n",
    "\n",
    "                            step_list.append(length_amplification_step)\n",
    "                        # add amplification values for the pixels after the last tgc-value\n",
    "                        if nr_px_already_included < len(array[0,:,0])+delay_samples:\n",
    "                            new_amplification_values.append(np.repeat(10**(float(tgc_db[-1])/20),len(array[0,:,0])+delay_samples-nr_px_already_included))\n",
    "\n",
    "                            step_list.append(len(array[0,:,0])+delay_samples-nr_px_already_included)\n",
    "                        \n",
    "                        new_amplification_values = np.squeeze(np.concatenate(new_amplification_values))\n",
    "\n",
    "                        # exclude possible delay samples and samples that lie behind the ROI\n",
    "                        new_amplification_values = new_amplification_values[delay_samples:delay_samples+len(array[0,:,0])]\n",
    "                        \n",
    "\n",
    "                        # divide the array by the amplification values \n",
    "                        array_without_tgc.append(array[:,:,frame_number]/new_amplification_values)\n",
    "\n",
    "                    array_without_tgc = np.array(array_without_tgc) # dimensions are not the same as in original array\n",
    "                    # move dimensions:\n",
    "                    array_without_tgc = np.moveaxis(array_without_tgc,0,-1)\n",
    "\n",
    "                    # insert step_list into tgc-file\n",
    "                    tgc = open(directory+'/'+dir+'/'+file[:-3]+'tgc','r')\n",
    "                    textdata = tgc.read()\n",
    "                    tgc.close()\n",
    "                    if not 'list with step informations' in textdata:\n",
    "                        textdata = textdata + '\\n\\nlist with step informations for each frame\\n' + str(step_list)\n",
    "                        tgc = open(directory+'/'+dir+'/'+file[:-3]+'tgc','w')\n",
    "                        tgc.write(textdata)\n",
    "                        tgc.close()\n",
    "\n",
    "\n",
    "                elif tgc_option == 'autogain_off':\n",
    "                    \n",
    "                    # check if tgc_mm starts with 0.00. If not, this method does not work \n",
    "                    if tgc_mm[0] != '0.00':\n",
    "                        print('ERROR: '+dir+' '+file+' -> tgc_mm does not start with 0.00')\n",
    "\n",
    "                    else: \n",
    "                        # create new array with amplification values (new_amplification_values = 10^(tgc-values/20))\n",
    "                        new_amplification_values = []\n",
    "                        array_without_tgc = []\n",
    "                        nr_px_already_included = 0\n",
    "                        for number_tgc_values in range(0,len(tgc_mm)-1):\n",
    "                            length_amplification_step = int(np.round(float(tgc_mm[number_tgc_values+1])*px_per_mm-float(tgc_mm[number_tgc_values])*px_per_mm))\n",
    "                            amplification_range = np.linspace(float(tgc_db[number_tgc_values]),float(tgc_db[number_tgc_values+1]), length_amplification_step) # amplification in dB over the range in px\n",
    "                            new_amplification_values.append(10**(amplification_range/20)) # amplification in linear values over the range in px\n",
    "                            nr_px_already_included += length_amplification_step\n",
    "\n",
    "                        # add amplification values for the pixels after the last tgc-value\n",
    "                        if nr_px_already_included < len(array[0,:,0])+delay_samples:\n",
    "                            new_amplification_values.append(np.repeat(10**(float(tgc_db[-1])/20),len(array[0,:,0])+delay_samples-nr_px_already_included))\n",
    "\n",
    "                        \n",
    "                        new_amplification_values = np.squeeze(np.concatenate(new_amplification_values))\n",
    "\n",
    "                        # exclude possible delay samples and samples that lie behind the ROI\n",
    "                        new_amplification_values = new_amplification_values[delay_samples:delay_samples+len(array[0,:,0])]\n",
    "\n",
    "                        # divide the array by the amplification values \n",
    "                        for frame_number in range(0,len(array[0,0,:])):\n",
    "                            array_without_tgc.append(array[:,:,frame_number]/new_amplification_values)\n",
    "\n",
    "                        array_without_tgc = np.array(array_without_tgc) # dimensions are not the same as in original array\n",
    "                        # move dimensions:\n",
    "                        array_without_tgc = np.moveaxis(array_without_tgc,0,-1)\n",
    "\n",
    "                # save the array without tgc in new file\n",
    "                np.save(directory+\"/\"+dir+'/'+file[:-4]+'_no_tgc.npy',array_without_tgc)\n",
    "\n",
    "                if 'C3' in file:\n",
    "                    count_all_C3 += 1\n",
    "                elif 'L15' in file:\n",
    "                    count_all_L15 += 1\n",
    "\n",
    "print('C3-Files where Autogain was OFF: '+str(count_autogain_off_C3)+' of '+str(count_all_C3)+' C3-Files total')\n",
    "print('L15-Files where Autogain was OFF: '+str(count_autogain_off_L15)+ ' of '+str(count_all_L15)+' L15-Files total')\n",
    "print('Recordings with more rf-frames than tgc-frames: '+str(recordings_with_more_rf_frames_than_tgc_frames))\n",
    "\n",
    "os.system('say \"TGC Berechnung abgeschlossen\"')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot signals with and without tgc\n",
    "\n",
    "dir = 'UKD013'\n",
    "transducer = 'C3_large'\n",
    "\n",
    "with_tgc = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data'+version+'/'+dir+'/'+transducer+'.rf.npy'\n",
    "without_tgc = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data'+version+'/'+dir+'/'+transducer+'.rf_no_tgc.npy'\n",
    "\n",
    "# # both arrays in one plot\n",
    "# # load arrays\n",
    "# array_with_tgc = np.load(with_tgc)\n",
    "# array_without_tgc = np.load(without_tgc)\n",
    "\n",
    "# # plot the first line of the first frame of both arrays\n",
    "# plt.plot(array_with_tgc[0,:,0])\n",
    "# plt.plot(array_without_tgc[0,:,0])\n",
    "# plt.show()\n",
    "\n",
    "#plot rf-data with and without tgc and the log-ratio between them\n",
    "file = with_tgc\n",
    "#choose scan line between 0 and 192 (for large scans)\n",
    "x_line = 96\n",
    "\n",
    "# choose rf.npy-file to display and which frame to display\n",
    "frame = 0\n",
    "\n",
    "# load data for plotting\n",
    "old_array = np.load(file).astype(float)\n",
    "new_array = np.load(file[:-4]+'_no_tgc.npy').astype(float)\n",
    "# define where to get tgc-values\n",
    "try: # auto gain ON\n",
    "    tgc = open(file[:-4]+'.tgc','r')\n",
    "    lines = tgc.readlines()\n",
    "    tgc.close()\n",
    "    if len(lines)-4 == len(old_array[0,0,:]): #old sorting\n",
    "        matches = re.findall('[\\d,\\.]*(?=mm)|[\\d,\\.]*(?=dB)', lines[frame+3])[::2]\n",
    "    else: \n",
    "        lines_with_timestamp =[]\n",
    "        for j,line in enumerate(lines):\n",
    "            if 'timestamp' in line:\n",
    "                lines_with_timestamp.append(j)\n",
    "        len_matches = lines_with_timestamp[frame+1] - lines_with_timestamp[frame]-1 # count how many tgc-informations are in the frame\n",
    "        line = str(lines[lines_with_timestamp[frame]:lines_with_timestamp[frame+1]])\n",
    "        matches = re.findall('[\\d,\\.]*(?=mm)|[\\d,\\.]*(?=dB)', line)[::2]\n",
    "    step_list = [int(float(x)) for x in re.findall('[\\d]*(?=,)', lines[-1])[::2]]\n",
    "except: # auto gain OFF\n",
    "    yaml_file = file[:-3]+'yaml'\n",
    "    with open(yaml_file, 'r') as stream:\n",
    "        yaml_file = yaml.safe_load(stream)  \n",
    "    \n",
    "    # clarius made a mistake in their program and calculated with 1540m/s even in 'breast' recordings (where the soundspeed should be 1450m/s)\n",
    "    # therefore 1540m/s is used for all recordings \n",
    "    # PROBLEM: they will change it back eventually -> so I inserted a workaround, where when the results dont fit, the soundspeed is changed to 1450m/s\n",
    "    # calculate number of pixels with the given soundspeed\n",
    "    px_number_1540 = (2*sampling_rate)/(1540*1e3)*imaging_depth\n",
    "    px_number_1450 = (2*sampling_rate)/(1450*1e3)*imaging_depth\n",
    "    actual_px_number = (yaml_file['size']['samples per line'])\n",
    "\n",
    "    if abs(px_number_1540-actual_px_number) > abs(px_number_1450-actual_px_number):\n",
    "        soundspeed = 1450\n",
    "    elif abs(px_number_1540-actual_px_number) < abs(px_number_1450-actual_px_number):\n",
    "        soundspeed = 1540\n",
    "\n",
    "    # calculate px/mm \n",
    "    px_per_mm = (2*sampling_rate)/(soundspeed*1e3)\n",
    "\n",
    "\n",
    "    lines = yaml_file['tgc']\n",
    "    lines = [item[:-2] for item in lines]\n",
    "    \n",
    "    tgc_mm = lines[::2]\n",
    "    \n",
    "    step_list = [int(round(float(step)*px_per_mm)) for step in tgc_mm]\n",
    "    \n",
    "# define parameters for plotting\n",
    "general_fontsize = 12\n",
    "general_figsize = (5,3)\n",
    "\n",
    "# plot array with tgc\n",
    "plt.figure(figsize=general_figsize)\n",
    "plt.plot(old_array[x_line,:,frame])\n",
    "m_count = 1\n",
    "# plot vertical line for each tgc-step\n",
    "for m in range(0,len(step_list)):\n",
    "    #plt.axvline(information_list[m], ymin=0, ymax=1, label='$' + matches[m_count] + ' dB$', color='orange')\n",
    "    m_count += 2\n",
    "plt.xlabel('Length in $pixel$', fontsize = general_fontsize)\n",
    "plt.ylabel('Amplitude', fontsize = general_fontsize)\n",
    "#plt.legend(loc = 'upper right')\n",
    "plt.title('Array with TGC', weight='bold', fontsize = general_fontsize)\n",
    "plt.show()\n",
    "\n",
    "# plot array without tgc\n",
    "plt.figure(figsize=general_figsize)\n",
    "plt.plot(hilbert((new_array[x_line,:,frame])))\n",
    "m_count = 1\n",
    "for m in range(0,len(step_list)):\n",
    "    #plt.axvline(information_list[m], ymin=0, ymax=1, label='$' + matches[m_count] + ' dB$', color='orange')\n",
    "    m_count += 2\n",
    "plt.xlabel('Length in $pixel$', fontsize = general_fontsize)\n",
    "plt.ylabel('Amplitude', fontsize = general_fontsize)\n",
    "#plt.legend(loc = 'upper right')\n",
    "plt.title('Array without TGC', weight='bold', fontsize = general_fontsize)\n",
    "plt.show()\n",
    "\n",
    "# plot log-ratio between file with and without tgc => shows the amount of amplificcation thats is done by the tgc\n",
    "plt.figure(figsize=general_figsize)\n",
    "ratio = np.abs(20*np.log10(np.divide(new_array[x_line,:,frame],old_array[x_line,:,frame])))\n",
    "plt.plot(ratio)\n",
    "for m in range(0,len(step_list)):\n",
    "    actual_step = step_list[m]\n",
    "    # plt.axvline(actual_step, ymin=0, ymax=1, label='$' + str(round(ratio[actual_step],2)) +' dB$', color='orange')\n",
    "plt.xlabel('Length in $pixel$', fontsize = general_fontsize)\n",
    "plt.ylabel('Amplification in $dB$', fontsize = general_fontsize)\n",
    "# plt.legend(loc = 'lower right')\n",
    "plt.title('TGC amplification', weight='bold', fontsize = general_fontsize)\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new folder with recordings for QUS analysis\n",
    "\n",
    "- just large recordings \n",
    "- just recordings where C3_large AND L15_large are available without tgc-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eb53128ebc44dcb1b23a5af2c0f9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create directory and copy all files with tgc for C3 and L15 to it\n",
    "version = version #'230726' # version of the data that should be copied\n",
    "start_directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data_'+version\n",
    "end_directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/C3_and_L15_without_TGC_'+version\n",
    "\n",
    "filter_autogain_off = True\n",
    "\n",
    "# create directory\n",
    "if not os.path.exists(end_directory):\n",
    "    os.makedirs(end_directory)\n",
    " \n",
    "    # copy files\n",
    "    for dir in tqdm(os.listdir(start_directory)):\n",
    "        C3_no_tgc = False\n",
    "        L15_no_tgc = False\n",
    "        # for loop through all recordings:\n",
    "        for file in os.listdir(start_directory+'/'+dir):\n",
    "            if not filter_autogain_off:\n",
    "                if 'C3_large.rf_no_tgc' in file:\n",
    "                    C3_no_tgc = True\n",
    "                if 'L15_large.rf_no_tgc' in file:\n",
    "                    L15_no_tgc = True\n",
    "            elif filter_autogain_off:\n",
    "                if 'C3_large.rf.tgc' in file:\n",
    "                    C3_no_tgc = True\n",
    "                if 'L15_large.rf.tgc' in file:\n",
    "                    L15_no_tgc = True\n",
    "        if C3_no_tgc and L15_no_tgc:\n",
    "            if not os.path.exists(end_directory+'/'+dir):\n",
    "                os.makedirs(end_directory+'/'+dir)\n",
    "            for file in os.listdir(start_directory+'/'+dir):\n",
    "                if 'C3_large.rf_no_tgc' in file:\n",
    "                    shutil.copy(start_directory+'/'+dir+'/'+file, end_directory+'/'+dir+'/'+file)\n",
    "                    # copy yaml file\n",
    "                    shutil.copy(start_directory+'/'+dir+'/'+file[:-11]+'.yaml', end_directory+'/'+dir+'/'+file[:-11]+'.yaml')\n",
    "                if 'L15_large.rf_no_tgc' in file:\n",
    "                    shutil.copy(start_directory+'/'+dir+'/'+file, end_directory+'/'+dir+'/'+file)\n",
    "                    # copy yaml file\n",
    "                    shutil.copy(start_directory+'/'+dir+'/'+file[:-11]+'.yaml', end_directory+'/'+dir+'/'+file[:-11]+'.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target list/csv based on RedCap-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for transformations\n",
    "\n",
    "transformation_frame_length = 2048\n",
    "transformation_transducer = 'L15'\n",
    "\n",
    "if transformation_transducer == 'C3':\n",
    "    transformation_number_number_of_frames = 27\n",
    "elif transformation_transducer == 'L15':\n",
    "    transformation_number_number_of_frames = 15\n",
    "\n",
    "# define Version (YYMMDD):\n",
    "version = '230607'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformation_transducer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# create classification with median of Fibroscan-Values as Cut-Off\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# get slide_table (csv) to get all frames of each patient separately\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m transducer \u001b[39m=\u001b[39m transformation_transducer\n\u001b[1;32m      5\u001b[0m frame_length \u001b[39m=\u001b[39m transformation_frame_length\n\u001b[1;32m      6\u001b[0m number_of_frames \u001b[39m=\u001b[39m transformation_number_number_of_frames\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformation_transducer' is not defined"
     ]
    }
   ],
   "source": [
    "# create classification with median of Fibroscan-Values as Cut-Off\n",
    "\n",
    "# get slide_table (csv) to get all frames of each patient separately\n",
    "transducer = transformation_transducer\n",
    "frame_length = transformation_frame_length\n",
    "number_of_frames = transformation_number_number_of_frames\n",
    "slide_table_df = pd.read_csv(r'/Volumes/Extreme_SSD/Targets/slide_table_'+transducer+'_'+str(frame_length)+'px_'+str(number_of_frames)+'frames_'+version+'.csv')\n",
    "\n",
    "frame_numbers = slide_table_df['Frame_number'].tolist()\n",
    "frame_numbers = sorted(frame_numbers)\n",
    "\n",
    "# get results out of RedCap-Survey (csv)\n",
    "df = pd.read_csv(r'/Users/jakobschaefer/Documents/REDCap_Survey_'+version+'.csv')\n",
    "\n",
    "Patient_ID = df['patients_id'].tolist()\n",
    "Median_E = df['median_e'].tolist()\n",
    "IQR_E = df['iqr_e'].tolist()\n",
    "Median_CAP = df['median_cap'].tolist()\n",
    "IQR_CAP = df['iqr_cap'].tolist()\n",
    "\n",
    "target_dict = {'Patient_ID': Patient_ID, 'Median_E': Median_E, 'IQR_E': IQR_E, 'Median_CAP': Median_CAP, 'IQR_CAP': IQR_CAP}\n",
    "\n",
    "# create binary classification for CAP based on Median of all Median_CAP-Values\n",
    "Median_Median_CAP = np.nanmedian(Median_CAP)\n",
    "target_dict['Median_Median_CAP'] = Median_Median_CAP\n",
    "\n",
    "classification_CAP = []\n",
    "for number in range(len(Median_CAP)):\n",
    "    if Median_CAP[number] <= Median_Median_CAP:\n",
    "        classification_CAP.append(0)\n",
    "    else:\n",
    "        classification_CAP.append(1)\n",
    "\n",
    "target_dict['classification_CAP'] = classification_CAP\n",
    "\n",
    "# create binary classification for E-Modulus based on Median of all Median_E-Values\n",
    "Median_Median_E = np.nanmedian(Median_E)\n",
    "target_dict['Median_Median_E'] = Median_Median_E\n",
    "\n",
    "classification_E = []\n",
    "for number in range(len(Median_E)):\n",
    "    if Median_E[number] <= Median_Median_E:\n",
    "        classification_E.append(0)\n",
    "    else:\n",
    "        classification_E.append(1)\n",
    "\n",
    "target_dict['classification_E'] = classification_E\n",
    "\n",
    "# create another dictionary wtih target values, but interpret every frame as a single patient\n",
    "target_dict_frames = {'Frame_Number': frame_numbers, 'Median_E': [], 'IQR_E': [], 'Median_CAP': [], 'IQR_CAP': [], 'Median_Median_CAP': [], 'classification_CAP': [], 'Median_Median_E': [], 'classification_E': []}\n",
    "\n",
    "for number in target_dict_frames['Frame_Number']:\n",
    "    target_dict_index_number = target_dict['Patient_ID'].index(number[:6])\n",
    "    target_dict_frames['Median_E'].append(target_dict['Median_E'][target_dict_index_number])\n",
    "    target_dict_frames['IQR_E'].append(target_dict['IQR_E'][target_dict_index_number])\n",
    "    target_dict_frames['Median_CAP'].append(target_dict['Median_CAP'][target_dict_index_number])\n",
    "    target_dict_frames['IQR_CAP'].append(target_dict['IQR_CAP'][target_dict_index_number])\n",
    "    target_dict_frames['Median_Median_CAP'].append(target_dict['Median_Median_CAP'])\n",
    "    target_dict_frames['classification_CAP'].append(target_dict['classification_CAP'][target_dict_index_number])\n",
    "    target_dict_frames['Median_Median_E'].append(target_dict['Median_Median_E'])\n",
    "    target_dict_frames['classification_E'].append(target_dict['classification_E'][target_dict_index_number])\n",
    "\n",
    "# safe target_dict_frames as csv\n",
    "target_frames_df = pd.DataFrame(target_dict_frames).dropna() # remove lines without values\n",
    "target_frames_df.to_csv('/Volumes/Extreme_SSD/Targets/labels_binary_classification_frames_'+version+'.csv', index=False)\n",
    "target_frames_df.to_excel('/Volumes/Extreme_SSD/Targets/labels_binary_classification_frames_'+version+'.xlsx', index=False)\n",
    "\n",
    "# safe target_dict as csv\n",
    "target_df = pd.DataFrame(target_dict).dropna() # remove lines without values\n",
    "target_df.to_csv('/Volumes/Extreme_SSD/Targets/labels_binary_classification_'+version+'.csv', index=False)\n",
    "target_df.to_excel('/Volumes/Extreme_SSD/Targets/labels_binary_classification_'+version+'.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many recordings from C3 and L15 exist with 2048 and 2500px\n",
    "\n",
    "list_2500px = os.listdir('/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Shortened_data_npy_2500px_230224')\n",
    "list_2048px = os.listdir('/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Shortened_data_npy_2048px_230224')\n",
    "\n",
    "C3_count = 0\n",
    "L15_count = 0\n",
    "\n",
    "for element in list_2048px:\n",
    "    if 'C3' in element:\n",
    "        C3_count += 1\n",
    "    if 'L15' in element:\n",
    "        L15_count += 1\n",
    "\n",
    "print('C3-Count: '+str(C3_count))\n",
    "print('L15-Count: '+str(L15_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut out unnecessary parts from DICOM-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# black out unnecessary parts in DICOM-files (e.g. Clarius-Label, frame rate, imaging depth)\n",
    "\n",
    "directory = 'Data/Finished_data'+version\n",
    "\n",
    "#black out additional data for curved array DICOMS\n",
    "for dir in os.listdir(directory):\n",
    "    if os.path.isdir(directory+\"/\"+dir):\n",
    "        for name in os.listdir(directory+\"/\"+dir):\n",
    "            if 'C3' in name and 'dcm' in name:\n",
    "                data = np.load(directory+\"/\"+dir+\"/\"+name)\n",
    "                data = data[0,:,:,0] # [frames, x, y, rgb]\n",
    "\n",
    "                # boundaries for image cropping (curved array)\n",
    "                x_min = 80\n",
    "                x_max = 720\n",
    "                y_min = 180\n",
    "                y_max = 620\n",
    "                # crop important image data\n",
    "                data = data[y_min:y_max,x_min:x_max]\n",
    "\n",
    "                # remove useless informations from clarius image\n",
    "                data[15:40,420:450] = 0.0 # clarius logo\n",
    "                data[400:,:50] = 0.0 # sample frequency\n",
    "                data[400:,610:] = 0.0 # deepth information\n",
    "                #plt.imshow(data)\n",
    "                #plt.show()\n",
    "\n",
    "                # overwrite old dcm-file with edited data\n",
    "                np.save(directory+\"/\"+dir+\"/\"+name,data)\n",
    "\n",
    "\n",
    "#black out additional data for linear array DICOMS\n",
    "for dir in os.listdir(directory):\n",
    "    if os.path.isdir(directory+\"/\"+dir):\n",
    "        for name in os.listdir(directory+\"/\"+dir):\n",
    "            if 'L15' in name and 'dcm' in name:\n",
    "                data = np.load(directory+\"/\"+dir+\"/\"+name)\n",
    "                data = data[0,:,:,:]\n",
    "                #plt.imshow(data)\n",
    "                #plt.show()\n",
    "\n",
    "                # boundaries for image cropping\n",
    "                x_min = 80\n",
    "                x_max = 720\n",
    "                y_min = 180\n",
    "                y_max = 620\n",
    "                # cut out unimportant image data\n",
    "                data = data[y_min:y_max,x_min:x_max]\n",
    "                #plt.imshow(data)\n",
    "                #plt.show()\n",
    "\n",
    "                # remove useless informations from clarius image\n",
    "                # clarius logo => RGB-Values are different\n",
    "                for y in range(0,y_max-y_min):\n",
    "                    for x in range(0,x_max-x_min):\n",
    "                        if data[y,x,0] != data[y,x,1] or data[y,x,0] != data[y,x,2]:\n",
    "                            data[y,x,:] = 0.0 \n",
    "                data[400:,:50] = 0.0 # sample frequency\n",
    "                data[400:,610:] = 0.0 # deepth information\n",
    "                data = data[:,:,0]\n",
    "                #plt.imshow(data)\n",
    "                #plt.show()\n",
    "\n",
    "                # overwrite old dcm-file with edited data\n",
    "                np.save(directory+\"/\"+dir+\"/\"+name,data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shorten Arrays and transform into H5-Files (Marco Gustav Edition)\n",
    "\n",
    "Define Parameter to shorten and split up arrays first. Those values will be used in all steps later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0d37ddf8a34969b86414cb0c7c0480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed frames because they were to short:  4\n",
      "Number of removed recordings because they had to few frames:  147\n",
      "Recordings with too short length:  ['UKD185/L15_large.rf_no_tgc.npy', 'UKD023/L15_large.rf_no_tgc.npy', 'UKD107/L15_large.rf_no_tgc.npy', 'UKD117/L15_large.rf_no_tgc.npy']\n",
      "Recordings with too few frames:  ['UKDFIB355/L15_large.rf_no_tgc.npy', 'UKDFIB354/L15_large.rf_no_tgc.npy', 'UKDFIB353/L15_large.rf_no_tgc.npy', 'UKDFIB352/L15_large.rf_no_tgc.npy', 'UKDFIB346/L15_large.rf_no_tgc.npy', 'UKDFIB347/L15_large.rf_no_tgc.npy', 'UKDFIB345/L15_large.rf_no_tgc.npy', 'UKDFIB341/L15_large.rf_no_tgc.npy', 'UKDFIB342/L15_large.rf_no_tgc.npy', 'UKDFIB343/L15_large.rf_no_tgc.npy', 'UKDFIB338/L15_large.rf_no_tgc.npy', 'UKDFIB339/L15_large.rf_no_tgc.npy', 'UKDFIB335/L15_large.rf_no_tgc.npy', 'UKDFIB337/L15_large.rf_no_tgc.npy', 'UKDFIB331/L15_large.rf_no_tgc.npy', 'UKDFIB332/L15_large.rf_no_tgc.npy', 'UKDFIB333/L15_large.rf_no_tgc.npy', 'UKDFIB334/L15_large.rf_no_tgc.npy', 'UKDFIB327/L15_large.rf_no_tgc.npy', 'UKDFIB328/L15_large.rf_no_tgc.npy', 'UKDFIB329/L15_large.rf_no_tgc.npy', 'UKDFIB330/L15_large.rf_no_tgc.npy', 'UKDFIB324/L15_large.rf_no_tgc.npy', 'UKDFIB325/L15_large.rf_no_tgc.npy', 'UKDFIB326/L15_large.rf_no_tgc.npy', 'UKDFIB320/L15_large.rf_no_tgc.npy', 'UKDFIB321/L15_large.rf_no_tgc.npy', 'UKDFIB323/L15_large.rf_no_tgc.npy', 'UKDFIB315/L15_large.rf_no_tgc.npy', 'UKDFIB317/L15_large.rf_no_tgc.npy', 'UKDFIB318/L15_large.rf_no_tgc.npy', 'UKDFIB319/L15_large.rf_no_tgc.npy', 'UKDFIB308/L15_large.rf_no_tgc.npy', 'UKDFIB310/L15_large.rf_no_tgc.npy', 'UKDFIB311/L15_large_1.rf_no_tgc.npy', 'UKDFIB311/L15_large.rf_no_tgc.npy', 'UKDFIB314/L15_large.rf_no_tgc.npy', 'UKDFIB305/L15_large.rf_no_tgc.npy', 'UKDFIB306/L15_large.rf_no_tgc.npy', 'UKDFIB307/L15_large.rf_no_tgc.npy', 'UKDFIB301/L15_large.rf_no_tgc.npy', 'UKDFIB302/L15_large.rf_no_tgc.npy', 'UKDFIB303/L15_large.rf_no_tgc.npy', 'UKDFIB304/L15_large.rf_no_tgc.npy', 'UKDFIB299/L15_large.rf_no_tgc.npy', 'UKDFIB300/L15_large.rf_no_tgc.npy', 'UKDFIB297/L15_large.rf_no_tgc.npy', 'UKDFIB298/L15_large.rf_no_tgc.npy', 'UKDFIB293/L15_large.rf_no_tgc.npy', 'UKDFIB294/L15_large.rf_no_tgc.npy', 'UKDFIB295/L15_large.rf_no_tgc.npy', 'UKDFIB290/L15_large.rf_no_tgc.npy', 'UKDFIB291/L15_large.rf_no_tgc.npy', 'UKDFIB292/L15_large.rf_no_tgc.npy', 'UKDFIB287/L15_large.rf_no_tgc.npy', 'UKDFIB289/L15_large.rf_no_tgc.npy', 'UKDFIB283/L15_large.rf_no_tgc.npy', 'UKDFIB285/L15_large.rf_no_tgc.npy', 'UKDFIB286/L15_large.rf_no_tgc.npy', 'UKDFIB280/L15_large.rf_no_tgc.npy', 'UKDFIB281/L15_large.rf_no_tgc.npy', 'UKDFIB282/L15_large.rf_no_tgc.npy', 'UKDFIB278/L15_large_1.rf_no_tgc.npy', 'UKDFIB278/L15_large.rf_no_tgc.npy', 'UKD192/L15_large.rf_no_tgc.npy', 'UKD250/L15_large.rf_no_tgc.npy', 'UKD200/L15_large.rf_no_tgc.npy', 'UKD247/L15_large.rf_no_tgc.npy', 'UKD217/L15_large.rf_no_tgc.npy', 'UKD210/L15_large.rf_no_tgc.npy', 'UKD185/L15_large.rf_no_tgc.npy', 'UKD233/L15_large.rf_no_tgc.npy', 'UKD235/L15_large.rf_no_tgc.npy', 'UKD223/L15_large.rf_no_tgc.npy', 'UKD225/L15_large.rf_no_tgc.npy', 'UKD246/L15_large.rf_no_tgc.npy', 'UKD202/L15_large.rf_no_tgc.npy', 'UKD232/L15_large.rf_no_tgc.npy', 'UKD227/L15_large.rf_no_tgc.npy', 'UKD251/L15_large.rf_no_tgc.npy', 'UKD254/L15_large.rf_no_tgc.npy', 'UKD240/L15_large.rf_no_tgc.npy', 'UKD201/L15_large.rf_no_tgc.npy', 'UKD270/L15_large.rf_no_tgc.npy', 'UKD212/L15_large.rf_no_tgc.npy', 'UKD196/L15_large.rf_no_tgc.npy', 'UKD204/L15_large.rf_no_tgc.npy', 'UKD205/L15_large.rf_no_tgc.npy', 'UKD252/L15_large_1.rf_no_tgc.npy', 'UKD252/L15_large.rf_no_tgc.npy', 'UKD241/L15_large.rf_no_tgc.npy', 'UKD190/L15_large.rf_no_tgc.npy', 'UKD226/L15_large.rf_no_tgc.npy', 'UKD231/L15_large.rf_no_tgc.npy', 'UKD031/L15_large.rf_no_tgc.npy', 'UKD224/L15_large.rf_no_tgc.npy', 'UKD194/L15_large.rf_no_tgc.npy', 'UKD239/L15_large.rf_no_tgc.npy', 'UKD187/L15_large.rf_no_tgc.npy', 'UKD214/L15_large.rf_no_tgc.npy', 'UKD245/L15_large.rf_no_tgc.npy', 'UKD242/L15_large.rf_no_tgc.npy', 'UKD273/L15_large.rf_no_tgc.npy', 'UKD244/L15_large.rf_no_tgc.npy', 'UKD253/L15_large.rf_no_tgc.npy', 'UKD269/L15_large.rf_no_tgc.npy', 'UKD249/L15_large.rf_no_tgc.npy', 'UKD215/L15_large.rf_no_tgc.npy', 'UKD221/L15_large.rf_no_tgc.npy', 'UKD220/L15_large.rf_no_tgc.npy', 'UKD274/L15_large.rf_no_tgc.npy', 'UKD218/L15_large.rf_no_tgc.npy', 'UKD271/L15_large.rf_no_tgc.npy', 'UKD198/L15_large.rf_no_tgc.npy', 'UKD195/L15_large.rf_no_tgc.npy', 'UKD197/L15_large.rf_no_tgc.npy', 'UKD213/L15_large.rf_no_tgc.npy', 'UKD229/L15_large.rf_no_tgc.npy', 'UKD234/L15_large.rf_no_tgc.npy', 'UKD211/L15_large.rf_no_tgc.npy', 'UKD256/L15_large.rf_no_tgc.npy', 'UKD207/L15_large.rf_no_tgc.npy', 'UKD186/L15_large.rf_no_tgc.npy', 'UKD255/L15_large.rf_no_tgc.npy', 'UKD236/L15_large.rf_no_tgc.npy', 'UKD272/L15_large.rf_no_tgc.npy', 'UKD169/L15_large.rf_no_tgc.npy', 'UKD248/L15_large.rf_no_tgc.npy', 'UKD191/L15_large.rf_no_tgc.npy', 'UKD203/L15_large.rf_no_tgc.npy', 'UKD189/L15_large.rf_no_tgc.npy', 'UKD188/L15_large.rf_no_tgc.npy', 'UKD199/L15_large.rf_no_tgc.npy', 'UKD222/L15_large.rf_no_tgc.npy', 'UKD230/L15_large.rf_no_tgc.npy', 'UKD243/L15_large.rf_no_tgc.npy', 'UKD257/L15_large.rf_no_tgc.npy', 'UKD275/L15_large.rf_no_tgc.npy', 'UKD258/L15_large.rf_no_tgc.npy', 'UKD259/L15_large.rf_no_tgc.npy', 'UKD260/L15_large.rf_no_tgc.npy', 'UKD261/L15_large.rf_no_tgc.npy', 'UKD262/L15_large.rf_no_tgc.npy', 'UKD264/L15_large.rf_no_tgc.npy', 'UKD265/L15_large.rf_no_tgc.npy', 'UKD266/L15_large.rf_no_tgc.npy', 'UKD277/L15_large.rf_no_tgc.npy']\n"
     ]
    }
   ],
   "source": [
    "# display lengths of arrays \n",
    "version= '230904'\n",
    "directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data_'+version\n",
    "transducer = 'L15_large'\n",
    "all_lengths = []\n",
    "all_frame_numbers = []\n",
    "too_short_length = []\n",
    "too_few_frames = []\n",
    "minimum_length = 2704\n",
    "minimum_frames = 15\n",
    "\n",
    "for dir in tqdm(os.listdir(directory)):\n",
    "    if os.path.isdir(directory+\"/\"+dir):\n",
    "        for name in os.listdir(directory+\"/\"+dir):\n",
    "            if transducer in name and 'rf_no_tgc.npy' in name:\n",
    "                try: data = np.load(directory+\"/\"+dir+\"/\"+name)\n",
    "                except: \n",
    "                    print('ERROR loading recording: '+dir+\"/\"+name)\n",
    "                    continue\n",
    "                if len(data[0,:,0]) < minimum_length:\n",
    "                    too_short_length.append(dir+\"/\"+name)\n",
    "                if len(data[0,0,:]) < minimum_frames:\n",
    "                    too_few_frames.append(dir+\"/\"+name)\n",
    "                one_length = len(data[0,:,0])\n",
    "                all_lengths.append(one_length)\n",
    "                one_frame_number = len(data[0,0,:])\n",
    "                all_frame_numbers.append(one_frame_number)\n",
    "\n",
    "removed_recordings_lengths = [i for i in all_lengths if i < minimum_length]\n",
    "removed_recordings_frame_numbers = [i for i in all_frame_numbers if i < minimum_frames]\n",
    "\n",
    "print('Number of removed frames because they were to short: ', len(removed_recordings_lengths))\n",
    "print('Number of removed recordings because they had to few frames: ', len(removed_recordings_frame_numbers))\n",
    "print('Recordings with too short length: ', too_short_length)\n",
    "print('Recordings with too few frames: ', too_few_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of frames:  14.084745762711865\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyk0lEQVR4nO3df3RU9Z3/8dcEyBAgkxhxMkkTaQRLTYNYFHFKTaGmCTa4Ut3doqCggIVO7Aa6GLEC0p42fHG7rd0qHL/tEs+hFH98G3+AhJ0lJhxLAI1GCEi2YDS0YQg1ZgZDCCH5fP9wue1IgEyAhJs8H+fcU+79vO+dz+dzJp2Xd+694zDGGAEAANhIVG93AAAAIFIEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsDe7sDl0pHR4fq6+sVGxsrh8PR290BAABdYIzRsWPHlJycrKios59n6bMBpr6+Xqmpqb3dDQAA0A2HDh1SSkrKWdv7bICJjY2V9NkEuFyuXu4NAADoilAopNTUVOtz/Gz6bIA5/bWRy+UiwAAAYDPnu/yDi3gBAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDt9NkH2QFAX9HeYbSrtlGBYIv++mmrmlraZIwUFzNIoRPn/vcVQ6KVMDRajc2R7cexOfb59nPIIe/IK3XLNVdqQFTP/+YgAQYALmMl1Ye14rV9Ohw80dtdAc7w6zcOKH7IIK28a4ymZCT16GvzFRIAXKZKqg9rwbp3CC+4rDUdb9P8de+opPpwj74uAQYALkPtHUYrXtsn09sdAbpoxWv71N7Rc+9YAgwAXIZ21TZy5gW2cjh4QrtqG3vs9QgwAHAZajhGeIH99OT7lgADAJchd+zg3u4CELGefN8SYADgMnRzWoKS4ggxsI+kuMG6OS2hx16PAAMAl6EBUQ4tvyNdPf90DaB7lt+R3qPPgyHAAMBlakpGklbPHMeZGFzWrhgySGtmjuvx58DwIDsAuIxNyUjSt9I9PImXY192x+ZJvACAcxoQ9dkHBYC/4SskAABgOwQYAABgOwQYAABgOwQYAABgO1zEe5G0dxjtOPixKj74qzr68FXnHLt/HNtOfe0Px75iSLSGxzrlcX32oLDeuOMDuNwQYC6CkurDevQPe9R0vK23uwKgj0uKG6zld6T3+DM3gMtNRF8hFRYWavz48YqNjZXb7da0adNUU1NjtX/44YdyOBydLi+++KJVV1dXp9zcXA0ZMkRut1uLFy/WqVOnwl6rrKxM48aNk9Pp1KhRo1RUVHRhI71ESqoPa/66dwgvAHrE4eAJLVj3jkqqD/d2V4BeFdEZmPLycvl8Po0fP16nTp3SY489puzsbO3bt09Dhw5VamqqDh8O/6N69tln9eSTT+r222+XJLW3tys3N1cej0fbt2/X4cOHdf/992vQoEH62c9+Jkmqra1Vbm6u5s+fr9/97nfaunWr5s6dq6SkJOXk5EQ2wuZmacCAyPbpovYOo5Uvva2YkycvyfEBoDMOSf/n/1XqWyMm8XUS+p7m5q7VmQvQ0NBgJJny8vKz1txwww3mwQcftNZff/11ExUVZQKBgLVt9erVxuVymdbWVmOMMY888oj5yle+Enac7373uyYnJ6fLfQsGg0aSCUrGsLCwsLCwsNhiCUpGkgkGg+f8nL+gu5CCwaAkKSGh81+frKysVFVVlebMmWNtq6io0JgxY5SYmGhty8nJUSgU0t69e62arKyssGPl5OSooqLiQroLAAD6iG5fxNvR0aH8/HxNnDhRGRkZndb89re/1XXXXaevfe1r1rZAIBAWXiRZ64FA4Jw1oVBILS0tiomJOeO1Wltb1draaq2HQqHP/lFfL7lckQ+wC3Z+8LFmr33rkhwbAM6n6IHxmnANPzGAPiYUkpKTz1vW7QDj8/lUXV2tN998s9P2lpYWrV+/XkuXLu3uS0SksLBQK1asOLNh6NDPlkvgpq8MkevK/9GRY63nLwaAi8QhyRM3WDd9JVXiGhj0Ne3tXSrr1ldIeXl52rhxo9544w2lpKR0WvPSSy/p+PHjuv/++8O2ezweHTlyJGzb6XWPx3POGpfL1enZF0lasmSJgsGgtRw6dKg7Q4uIf19Are0dl/x1AODzlt+RzgW86NciCjDGGOXl5am4uFilpaVKS0s7a+1vf/tb/cM//IOuuuqqsO1er1d79uxRQ0ODtc3v98vlcik9Pd2q2bp1a9h+fr9fXq/3rK/ndDrlcrnClkuppPqwFnD7NIAelhQ3WKtnjuM5MOj3IvoKyefzaf369XrllVcUGxtrXbMSFxcXdmbkwIED2rZtm15//fUzjpGdna309HTdd999WrVqlQKBgB5//HH5fD45nU5J0vz58/XrX/9ajzzyiB588EGVlpbqhRde0KZNmy5krBdNe4fRitf2yZyjZmh0lGZ50ySHfZ/+ybH777Ht1Nf+cGyexAucyWGMOdfncHixo/M/mrVr12r27NnW+mOPPaZ169bpww8/VFTUmSd5PvroIy1YsEBlZWUaOnSoZs2apZUrV2rgwL/lqbKyMi1cuFD79u1TSkqKli5dGvYa5xMKhRQXF6dgMHjRz8ZUHPxY9/zfHeet+/28W+QdyQV2AAB0VVc/vyMKMHZyKQPMK1V/0b9sqDpv3VPTb9CdN3zhor42AAB9WVc/v/k16m5wxw6+qHUAACAyBJhuuDktQUlxg3W2b6Ed+uxCu5vTOn/AHwAAuDAEmG4YEOXQ8js+u2Pq8yHm9Dq3OAIAcOkQYLppSkaSVs8cJ09c+NdEHm5xBADgkuv2k3jxWYj5VrpHu2ob1XDshNyx3OIIAEBPIMBcoAFRDm6VBgCgh/EVEgAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsJ2IAkxhYaHGjx+v2NhYud1uTZs2TTU1NWfUVVRU6Jvf/KaGDh0ql8ulzMxMtbS0WO2NjY2aMWOGXC6X4uPjNWfOHH366adhx9i9e7duvfVWDR48WKmpqVq1alU3hwgAAPqaiAJMeXm5fD6fduzYIb/fr7a2NmVnZ6u5udmqqaio0JQpU5Sdna1du3bprbfeUl5enqKi/vZSM2bM0N69e+X3+7Vx40Zt27ZNDz30kNUeCoWUnZ2tESNGqLKyUk8++aSeeOIJPfvssxdhyAAAwO4cxhjT3Z2PHj0qt9ut8vJyZWZmSpJuueUWfetb39JPfvKTTvd5//33lZ6errfeeks33XSTJKmkpETf/va39ec//1nJyclavXq1fvSjHykQCCg6OlqS9Oijj+rll1/W/v37u9S3UCikuLg4BYNBuVyu7g4RAAD0oK5+fl/QNTDBYFCSlJCQIElqaGjQzp075Xa79bWvfU2JiYn6xje+oTfffNPap6KiQvHx8VZ4kaSsrCxFRUVp586dVk1mZqYVXiQpJydHNTU1+uSTTzrtS2trq0KhUNgCAAD6pm4HmI6ODuXn52vixInKyMiQJH3wwQeSpCeeeELz5s1TSUmJxo0bp9tuu01/+tOfJEmBQEButzvsWAMHDlRCQoICgYBVk5iYGFZzev10zecVFhYqLi7OWlJTU7s7NAAAcJnrdoDx+Xyqrq7Whg0brG0dHR2SpO9973t64IEH9NWvflW/+MUvNHr0aP3nf/7nhff2HJYsWaJgMGgthw4duqSvBwAAes/A7uyUl5dnXXybkpJibU9KSpIkpaenh9Vfd911qqurkyR5PB41NDSEtZ86dUqNjY3yeDxWzZEjR8JqTq+frvk8p9Mpp9PZneEAAACbiegMjDFGeXl5Ki4uVmlpqdLS0sLav/jFLyo5OfmMW6v/53/+RyNGjJAkeb1eNTU1qbKy0movLS1VR0eHJkyYYNVs27ZNbW1tVo3f79fo0aN1xRVXRDZCAADQ50QUYHw+n9atW6f169crNjZWgUBAgUDAesaLw+HQ4sWL9atf/UovvfSSDhw4oKVLl2r//v2aM2eOpM/OxkyZMkXz5s3Trl279Mc//lF5eXmaPn26kpOTJUn33nuvoqOjNWfOHO3du1fPP/+8nnrqKS1atOgiDx8AANhRRLdROxyOTrevXbtWs2fPttZXrlypp59+Wo2NjRo7dqxWrVqlr3/961Z7Y2Oj8vLy9NprrykqKkp33323fvWrX2nYsGFWze7du+Xz+fTWW29p+PDhevjhh1VQUNDlgXEbNQAA9tPVz+8Leg7M5YwAAwCA/fTIc2AAAAB6AwEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYTkQBprCwUOPHj1dsbKzcbremTZummpqasJpJkybJ4XCELfPnzw+rqaurU25uroYMGSK3263Fixfr1KlTYTVlZWUaN26cnE6nRo0apaKiou6NEAAA9DkRBZjy8nL5fD7t2LFDfr9fbW1tys7OVnNzc1jdvHnzdPjwYWtZtWqV1dbe3q7c3FydPHlS27dv13PPPaeioiItW7bMqqmtrVVubq4mT56sqqoq5efna+7cudqyZcsFDhcAAPQFDmOM6e7OR48eldvtVnl5uTIzMyV9dgbmhhtu0C9/+ctO99m8ebOmTp2q+vp6JSYmSpLWrFmjgoICHT16VNHR0SooKNCmTZtUXV1t7Td9+nQ1NTWppKSkS30LhUKKi4tTMBiUy+Xq7hABAEAP6urn9wVdAxMMBiVJCQkJYdt/97vfafjw4crIyNCSJUt0/Phxq62iokJjxoyxwosk5eTkKBQKae/evVZNVlZW2DFzcnJUUVFx1r60trYqFAqFLQAAoG8a2N0dOzo6lJ+fr4kTJyojI8Pafu+992rEiBFKTk7W7t27VVBQoJqaGv3hD3+QJAUCgbDwIslaDwQC56wJhUJqaWlRTEzMGf0pLCzUihUrujscAABgI90OMD6fT9XV1XrzzTfDtj/00EPWv8eMGaOkpCTddtttOnjwoEaOHNn9np7HkiVLtGjRIms9FAopNTX1kr0eAADoPd36CikvL08bN27UG2+8oZSUlHPWTpgwQZJ04MABSZLH49GRI0fCak6vezyec9a4XK5Oz75IktPplMvlClsAAEDfFFGAMcYoLy9PxcXFKi0tVVpa2nn3qaqqkiQlJSVJkrxer/bs2aOGhgarxu/3y+VyKT093arZunVr2HH8fr+8Xm8k3QUAAH1URAHG5/Np3bp1Wr9+vWJjYxUIBBQIBNTS0iJJOnjwoH7yk5+osrJSH374oV599VXdf//9yszM1PXXXy9Jys7OVnp6uu677z6999572rJlix5//HH5fD45nU5J0vz58/XBBx/okUce0f79+/XMM8/ohRde0MKFCy/y8AEAgB1FdBu1w+HodPvatWs1e/ZsHTp0SDNnzlR1dbWam5uVmpqq73znO3r88cfDvtL56KOPtGDBApWVlWno0KGaNWuWVq5cqYED/3ZJTllZmRYuXKh9+/YpJSVFS5cu1ezZs7s8MG6jBgDAfrr6+X1Bz4G5nBFgAACwnx55DgwAAEBvIMAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbIcAAAADbiSjAFBYWavz48YqNjZXb7da0adNUU1PTaa0xRrfffrscDodefvnlsLa6ujrl5uZqyJAhcrvdWrx4sU6dOhVWU1ZWpnHjxsnpdGrUqFEqKiqKaGAAAKDviijAlJeXy+fzaceOHfL7/Wpra1N2draam5vPqP3lL38ph8Nxxvb29nbl5ubq5MmT2r59u5577jkVFRVp2bJlVk1tba1yc3M1efJkVVVVKT8/X3PnztWWLVu6MUQAANDXOIwxprs7Hz16VG63W+Xl5crMzLS2V1VVaerUqXr77beVlJSk4uJiTZs2TZK0efNmTZ06VfX19UpMTJQkrVmzRgUFBTp69Kiio6NVUFCgTZs2qbq62jrm9OnT1dTUpJKSki71LRQKKS4uTsFgUC6Xq7tDBAAAPairn98XdA1MMBiUJCUkJFjbjh8/rnvvvVdPP/20PB7PGftUVFRozJgxVniRpJycHIVCIe3du9eqycrKCtsvJydHFRUVZ+1La2urQqFQ2AIAAPqmbgeYjo4O5efna+LEicrIyLC2L1y4UF/72td05513drpfIBAICy+SrPVAIHDOmlAopJaWlk6PW1hYqLi4OGtJTU3t7tAAAMBlbmB3d/T5fKqurtabb75pbXv11VdVWlqqd99996J0LhJLlizRokWLrPVQKESIAQCgj+pWgMnLy9PGjRu1bds2paSkWNtLS0t18OBBxcfHh9XffffduvXWW1VWViaPx6Ndu3aFtR85ckSSrK+cPB6Pte3va1wul2JiYjrtk9PplNPp7M5wItbeYbTj4Meq+OCvkhzyjrxSt1xzpQZEnXnRMgAAuPgiCjDGGD388MMqLi5WWVmZ0tLSwtofffRRzZ07N2zbmDFj9Itf/EJ33HGHJMnr9eqnP/2pGhoa5Ha7JUl+v18ul0vp6elWzeuvvx52HL/fL6/XG9noLoGS6sN69A971HS8zdr26zcOKH7IIK28a4ymZCT1Yu8AAOgfIroL6fvf/77Wr1+vV155RaNHj7a2x8XFnfXMiMPhCLsLqb29XTfccIOSk5O1atUqBQIB3XfffZo7d65+9rOfSfrsNuqMjAz5fD49+OCDKi0t1Q9+8ANt2rRJOTk5XerrpbgLqaT6sOave+ecNWtmjiPEAADQTZfkLqTVq1crGAxq0qRJSkpKspbnn3++y8cYMGCANm7cqAEDBsjr9WrmzJm6//779eMf/9iqSUtL06ZNm+T3+zV27Fj9/Oc/129+85suh5dLob3D6IlX9563bsVr+9Te0e070wEAQBdc0HNgLmcX+wxMxcGPdc//3dGl2t/Pu0XekVde8GsCANDf9MhzYPqThmMnLkktAACIHAGmi9yxgy9JLQAAiBwBpotuTkuQx3X+27ST4gbr5rSE89YBAIDuI8B00YAoh574h6+ct275Hek8DwYAgEuMABOBKRlJWjNznOKHDDqj7Yohg7iFGgCAHtLtnxLor6ZkJOlb6R6exAsAQC8iwHTDgCiHJl47XBOvHd7bXQEAoF/iKyQAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7EQWYwsJCjR8/XrGxsXK73Zo2bZpqamrCar73ve9p5MiRiomJ0VVXXaU777xT+/fvD6upq6tTbm6uhgwZIrfbrcWLF+vUqVNhNWVlZRo3bpycTqdGjRqloqKi7o0QAAD0OREFmPLycvl8Pu3YsUN+v19tbW3Kzs5Wc3OzVXPjjTdq7dq1ev/997VlyxYZY5Sdna329nZJUnt7u3Jzc3Xy5Elt375dzz33nIqKirRs2TLrGLW1tcrNzdXkyZNVVVWl/Px8zZ07V1u2bLlIwwYAAHbmMMaY7u589OhRud1ulZeXKzMzs9Oa3bt3a+zYsTpw4IBGjhypzZs3a+rUqaqvr1diYqIkac2aNSooKNDRo0cVHR2tgoICbdq0SdXV1dZxpk+frqamJpWUlHSpb6FQSHFxcQoGg3K5XN0dIgAA6EFd/fy+oGtggsGgJCkhIaHT9ubmZq1du1ZpaWlKTU2VJFVUVGjMmDFWeJGknJwchUIh7d2716rJysoKO1ZOTo4qKioupLsAAKCP6HaA6ejoUH5+viZOnKiMjIywtmeeeUbDhg3TsGHDtHnzZvn9fkVHR0uSAoFAWHiRZK0HAoFz1oRCIbW0tHTan9bWVoVCobAFAAD0Td0OMD6fT9XV1dqwYcMZbTNmzNC7776r8vJyfelLX9I///M/68SJExfU0fMpLCxUXFyctZw+4wMAAPqebgWYvLw8bdy4UW+88YZSUlLOaI+Li9O1116rzMxMvfTSS9q/f7+Ki4slSR6PR0eOHAmrP73u8XjOWeNyuRQTE9Npn5YsWaJgMGgthw4d6s7QAACADUQUYIwxysvLU3FxsUpLS5WWltalfYwxam1tlSR5vV7t2bNHDQ0NVo3f75fL5VJ6erpVs3Xr1rDj+P1+eb3es76O0+mUy+UKWwAAQN8UUYDx+Xxat26d1q9fr9jYWAUCAQUCAeu6lA8++ECFhYWqrKxUXV2dtm/frn/6p39STEyMvv3tb0uSsrOzlZ6ervvuu0/vvfeetmzZoscff1w+n09Op1OSNH/+fH3wwQd65JFHtH//fj3zzDN64YUXtHDhwos8fAAAYEcR3UbtcDg63b527VrNnj1b9fX1mjt3riorK/XJJ58oMTFRmZmZWrZsmUaPHm3Vf/TRR1qwYIHKyso0dOhQzZo1SytXrtTAgQOtmrKyMi1cuFD79u1TSkqKli5dqtmzZ3d5YNxGDQCA/XT18/uCngNzOSPAAABgPz3yHBgAAIDeQIABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2E1GAKSws1Pjx4xUbGyu3261p06appqbGam9sbNTDDz+s0aNHKyYmRldffbV+8IMfKBgMhh2nrq5Oubm5GjJkiNxutxYvXqxTp06F1ZSVlWncuHFyOp0aNWqUioqKuj9KAADQp0QUYMrLy+Xz+bRjxw75/X61tbUpOztbzc3NkqT6+nrV19fr3/7t31RdXa2ioiKVlJRozpw51jHa29uVm5urkydPavv27XruuedUVFSkZcuWWTW1tbXKzc3V5MmTVVVVpfz8fM2dO1dbtmy5SMMGAAB25jDGmO7ufPToUbndbpWXlyszM7PTmhdffFEzZ85Uc3OzBg4cqM2bN2vq1Kmqr69XYmKiJGnNmjUqKCjQ0aNHFR0drYKCAm3atEnV1dXWcaZPn66mpiaVlJR0qW+hUEhxcXEKBoNyuVzdHSIAAOhBXf38vqBrYE5/NZSQkHDOGpfLpYEDB0qSKioqNGbMGCu8SFJOTo5CoZD27t1r1WRlZYUdJycnRxUVFWd9ndbWVoVCobAFAAD0Td0OMB0dHcrPz9fEiROVkZHRac1f//pX/eQnP9FDDz1kbQsEAmHhRZK1HggEzlkTCoXU0tLS6WsVFhYqLi7OWlJTU7s7NAAAcJnrdoDx+Xyqrq7Whg0bOm0PhULKzc1Venq6nnjiie6+TJctWbJEwWDQWg4dOnTJXxMAAPSOgd3ZKS8vTxs3btS2bduUkpJyRvuxY8c0ZcoUxcbGqri4WIMGDbLaPB6Pdu3aFVZ/5MgRq+30/57e9vc1LpdLMTExnfbJ6XTK6XR2ZzgAAMBmIjoDY4xRXl6eiouLVVpaqrS0tDNqQqGQsrOzFR0drVdffVWDBw8Oa/d6vdqzZ48aGhqsbX6/Xy6XS+np6VbN1q1bw/bz+/3yer2RdBcAAPRREQUYn8+ndevWaf369YqNjVUgEFAgELCuSzkdXpqbm/Xb3/5WoVDIqmlvb5ckZWdnKz09Xffdd5/ee+89bdmyRY8//rh8Pp91BmX+/Pn64IMP9Mgjj2j//v165pln9MILL2jhwoUXefgAAMCOIrqN2uFwdLp97dq1mj17tsrKyjR58uROa2pra/XFL35RkvTRRx9pwYIFKisr09ChQzVr1iytXLnSulNJ+uxBdgsXLtS+ffuUkpKipUuXavbs2V0eGLdRAwBgP139/L6g58BczggwAADYT488BwYAAKA3EGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtEGAAAIDtRBRgCgsLNX78eMXGxsrtdmvatGmqqakJq3n22Wc1adIkuVwuORwONTU1nXGcxsZGzZgxQy6XS/Hx8ZozZ44+/fTTsJrdu3fr1ltv1eDBg5WamqpVq1ZFPjoAANAnRRRgysvL5fP5tGPHDvn9frW1tSk7O1vNzc1WzfHjxzVlyhQ99thjZz3OjBkztHfvXvn9fm3cuFHbtm3TQw89ZLWHQiFlZ2drxIgRqqys1JNPPqknnnhCzz77bDeGCAAA+hqHMcZ0d+ejR4/K7XarvLxcmZmZYW1lZWWaPHmyPvnkE8XHx1vb33//faWnp+utt97STTfdJEkqKSnRt7/9bf35z39WcnKyVq9erR/96EcKBAKKjo6WJD366KN6+eWXtX///i71LRQKKS4uTsFgUC6Xq7tDBAAAPairn98XdA1MMBiUJCUkJHR5n4qKCsXHx1vhRZKysrIUFRWlnTt3WjWZmZlWeJGknJwc1dTU6JNPPun0uK2trQqFQmELAADom7odYDo6OpSfn6+JEycqIyOjy/sFAgG53e6wbQMHDlRCQoICgYBVk5iYGFZzev10zecVFhYqLi7OWlJTUyMZDgAAsJFuBxifz6fq6mpt2LDhYvan25YsWaJgMGgthw4d6u0uAQCAS2Rgd3bKy8uzLr5NSUmJaF+Px6OGhoawbadOnVJjY6M8Ho9Vc+TIkbCa0+unaz7P6XTK6XRG1BcAAGBPEZ2BMcYoLy9PxcXFKi0tVVpaWsQv6PV61dTUpMrKSmtbaWmpOjo6NGHCBKtm27Ztamtrs2r8fr9Gjx6tK664IuLXBAAAfUtEAcbn82ndunVav369YmNjFQgEFAgE1NLSYtUEAgFVVVXpwIEDkqQ9e/aoqqpKjY2NkqTrrrtOU6ZM0bx587Rr1y798Y9/VF5enqZPn67k5GRJ0r333qvo6GjNmTNHe/fu1fPPP6+nnnpKixYtuljjBgAAdmYiIKnTZe3atVbN8uXLz1vz8ccfm3vuuccMGzbMuFwu88ADD5hjx46FvdZ7771nvv71rxun02m+8IUvmJUrV0bSVRMMBo0kEwwGI9oPAAD0nq5+fl/Qc2AuZzwHBgAA++mR58AAAAD0BgIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwHQIMAACwnYG93QE7ae8w2lXbqIZjJ+SOHayb0xI0IMrR290CAKDfIcB0UUn1Ya14bZ8OB09Y25LiBmv5HemakpHUiz0DAKD/4SukLiipPqwF694JCy+SFAie0IJ176ik+nAv9QwAgP6JAHMe7R1GK17bJ9NJ2+ltK17bp/aOzioAAMClQIA5j121jWecefl7RtLh4Antqm3suU4BANDPEWDOo+HY2cNLd+oAAMCFI8Cchzt28EWtAwAAF44Acx43pyUoKW6wznaztEOf3Y10c1pCT3YLAIB+jQBzHgOiHFp+R7oknRFiTq8vvyOd58EAANCDCDBdMCUjSatnjpMnLvxrIk/cYK2eOY7nwAAA0MN4kF0XTclI0rfSPTyJFwCAywABJgIDohzyjryyt7sBAEC/x1dIAADAdggwAADAdggwAADAdggwAADAdggwAADAdiIKMIWFhRo/frxiY2Pldrs1bdo01dTUhNWcOHFCPp9PV155pYYNG6a7775bR44cCaupq6tTbm6uhgwZIrfbrcWLF+vUqVNhNWVlZRo3bpycTqdGjRqloqKi7o0QAAD0OREFmPLycvl8Pu3YsUN+v19tbW3Kzs5Wc3OzVbNw4UK99tprevHFF1VeXq76+nrdddddVnt7e7tyc3N18uRJbd++Xc8995yKioq0bNkyq6a2tla5ubmaPHmyqqqqlJ+fr7lz52rLli0XYcgAAMDuHMYY092djx49KrfbrfLycmVmZioYDOqqq67S+vXr9Y//+I+SpP379+u6665TRUWFbrnlFm3evFlTp05VfX29EhMTJUlr1qxRQUGBjh49qujoaBUUFGjTpk2qrq62Xmv69OlqampSSUlJl/oWCoUUFxenYDAol8vV3SECAIAe1NXP7wu6BiYYDEqSEhI++yHDyspKtbW1KSsry6r58pe/rKuvvloVFRWSpIqKCo0ZM8YKL5KUk5OjUCikvXv3WjV/f4zTNaeP0ZnW1laFQqGwBQAA9E3dfhJvR0eH8vPzNXHiRGVkZEiSAoGAoqOjFR8fH1abmJioQCBg1fx9eDndfrrtXDWhUEgtLS2KiYk5oz+FhYVasWLFGdsJMgAA2Mfpz+3zfUHU7QDj8/lUXV2tN998s7uHuKiWLFmiRYsWWet/+ctflJ6ertTU1F7sFQAA6I5jx44pLi7urO3dCjB5eXnauHGjtm3bppSUFGu7x+PRyZMn1dTUFHYW5siRI/J4PFbNrl27wo53+i6lv6/5/J1LR44ckcvl6vTsiyQ5nU45nU5rfdiwYTp06JBiY2PlcFy8H1wMhUJKTU3VoUOHuLami5izyDFnkWG+IsecRY45i1x35swYo2PHjik5OfmcdREFGGOMHn74YRUXF6usrExpaWlh7TfeeKMGDRqkrVu36u6775Yk1dTUqK6uTl6vV5Lk9Xr105/+VA0NDXK73ZIkv98vl8ul9PR0q+b1118PO7bf77eO0RVRUVFh4epic7lcvIEjxJxFjjmLDPMVOeYscsxZ5CKds3OdeTktogDj8/m0fv16vfLKK4qNjbWuWYmLi1NMTIzi4uI0Z84cLVq0SAkJCXK5XHr44Yfl9Xp1yy23SJKys7OVnp6u++67T6tWrVIgENDjjz8un89nnUGZP3++fv3rX+uRRx7Rgw8+qNLSUr3wwgvatGlTJN0FAAB9VER3Ia1evVrBYFCTJk1SUlKStTz//PNWzS9+8QtNnTpVd999tzIzM+XxePSHP/zBah8wYIA2btyoAQMGyOv1aubMmbr//vv14x//2KpJS0vTpk2b5Pf7NXbsWP385z/Xb37zG+Xk5FyEIQMAALuL+Cuk8xk8eLCefvppPf3002etGTFixBlfEX3epEmT9O6770bSvR7hdDq1fPnysOttcG7MWeSYs8gwX5FjziLHnEXuUs7ZBT3IDgAAoDfwY44AAMB2CDAAAMB2CDAAAMB2CDAAAMB2CDARevrpp/XFL35RgwcP1oQJE854qnB/9cQTT8jhcIQtX/7yl632EydOyOfz6corr9SwYcN09913n/G05b5u27ZtuuOOO5ScnCyHw6GXX345rN0Yo2XLlikpKUkxMTHKysrSn/70p7CaxsZGzZgxQy6XS/Hx8ZozZ44+/fTTHhxFzzrfnM2ePfuM992UKVPCavrTnBUWFmr8+PGKjY2V2+3WtGnTVFNTE1bTlb/Furo65ebmasiQIXK73Vq8eLFOnTrVk0PpMV2Zs0mTJp3xPps/f35YTX+Zs9WrV+v666+3Hkzn9Xq1efNmq70n318EmAg8//zzWrRokZYvX6533nlHY8eOVU5OjhoaGnq7a5eFr3zlKzp8+LC1/P3vZC1cuFCvvfaaXnzxRZWXl6u+vl533XVXL/a25zU3N2vs2LFnfcTAqlWr9Ktf/Upr1qzRzp07NXToUOXk5OjEiRNWzYwZM7R37175/X7r5zweeuihnhpCjzvfnEnSlClTwt53v//978Pa+9OclZeXy+fzaceOHfL7/Wpra1N2draam5utmvP9Lba3tys3N1cnT57U9u3b9dxzz6moqEjLli3rjSFdcl2ZM0maN29e2Pts1apVVlt/mrOUlBStXLlSlZWVevvtt/XNb35Td955p/bu3Suph99fBl128803G5/PZ623t7eb5ORkU1hY2Iu9ujwsX77cjB07ttO2pqYmM2jQIPPiiy9a295//30jyVRUVPRQDy8vkkxxcbG13tHRYTwej3nyySetbU1NTcbpdJrf//73xhhj9u3bZySZt956y6rZvHmzcTgc5i9/+UuP9b23fH7OjDFm1qxZ5s477zzrPv19zhoaGowkU15ebozp2t/i66+/bqKiokwgELBqVq9ebVwul2ltbe3ZAfSCz8+ZMcZ84xvfMP/yL/9y1n36+5xdccUV5je/+U2Pv784A9NFJ0+eVGVlpbKysqxtUVFRysrKUkVFRS/27PLxpz/9ScnJybrmmms0Y8YM1dXVSZIqKyvV1tYWNndf/vKXdfXVVzN3/6u2tlaBQCBsjuLi4jRhwgRrjioqKhQfH6+bbrrJqsnKylJUVJR27tzZ432+XJSVlcntdmv06NFasGCBPv74Y6utv89ZMBiUJCUkJEjq2t9iRUWFxowZo8TERKsmJydHoVDI+q/svuzzc3ba7373Ow0fPlwZGRlasmSJjh8/brX11zlrb2/Xhg0b1NzcLK/X2+Pvr279GnV/9Ne//lXt7e1hky5JiYmJ2r9/fy/16vIxYcIEFRUVafTo0Tp8+LBWrFihW2+9VdXV1QoEAoqOjg77hXLps7k7/Xta/d3peejs/XW6LRAIWD+AetrAgQOVkJDQb+dxypQpuuuuu5SWlqaDBw/qscce0+23366KigoNGDCgX89ZR0eH8vPzNXHiRGVkZEhSl/4WA4FAp+/D0219WWdzJkn33nuvRowYoeTkZO3evVsFBQWqqamxfianv83Znj175PV6deLECQ0bNkzFxcVKT09XVVVVj76/CDC4KG6//Xbr39dff70mTJigESNG6IUXXlBMTEwv9gx92fTp061/jxkzRtdff71GjhypsrIy3Xbbbb3Ys97n8/lUXV0ddi0azu1sc/b310yNGTNGSUlJuu2223Tw4EGNHDmyp7vZ60aPHq2qqioFg0G99NJLmjVrlsrLy3u8H3yF1EXDhw/XgAEDzria+siRI/J4PL3Uq8tXfHy8vvSlL+nAgQPyeDw6efKkmpqawmqYu785PQ/nen95PJ4zLhg/deqUGhsbmcf/dc0112j48OE6cOCApP47Z3l5edq4caPeeOMNpaSkWNu78rfo8Xg6fR+ebuurzjZnnZkwYYIkhb3P+tOcRUdHa9SoUbrxxhtVWFiosWPH6qmnnurx9xcBpouio6N14403auvWrda2jo4Obd26VV6vtxd7dnn69NNPdfDgQSUlJenGG2/UoEGDwuaupqZGdXV1zN3/SktLk8fjCZujUCiknTt3WnPk9XrV1NSkyspKq6a0tFQdHR3W/6H2d3/+85/18ccfKykpSVL/mzNjjPLy8lRcXKzS0lKlpaWFtXflb9Hr9WrPnj1hwc/v98vlcik9Pb1nBtKDzjdnnamqqpKksPdZf5qzz+vo6FBra2vPv78uxhXI/cWGDRuM0+k0RUVFZt++feahhx4y8fHxYVdT91c//OEPTVlZmamtrTV//OMfTVZWlhk+fLhpaGgwxhgzf/58c/XVV5vS0lLz9ttvG6/Xa7xeby/3umcdO3bMvPvuu+bdd981ksy///u/m3fffdd89NFHxhhjVq5caeLj480rr7xidu/ebe68806TlpZmWlparGNMmTLFfPWrXzU7d+40b775prn22mvNPffc01tDuuTONWfHjh0z//qv/2oqKipMbW2t+e///m8zbtw4c+2115oTJ05Yx+hPc7ZgwQITFxdnysrKzOHDh63l+PHjVs35/hZPnTplMjIyTHZ2tqmqqjIlJSXmqquuMkuWLOmNIV1y55uzAwcOmB//+Mfm7bffNrW1teaVV14x11xzjcnMzLSO0Z/m7NFHHzXl5eWmtrbW7N692zz66KPG4XCY//qv/zLG9Oz7iwATof/4j/8wV199tYmOjjY333yz2bFjR2936bLw3e9+1yQlJZno6GjzhS98wXz3u981Bw4csNpbWlrM97//fXPFFVeYIUOGmO985zvm8OHDvdjjnvfGG28YSWcss2bNMsZ8div10qVLTWJionE6nea2224zNTU1Ycf4+OOPzT333GOGDRtmXC6XeeCBB8yxY8d6YTQ941xzdvz4cZOdnW2uuuoqM2jQIDNixAgzb968M/6Doj/NWWdzJcmsXbvWqunK3+KHH35obr/9dhMTE2OGDx9ufvjDH5q2trYeHk3PON+c1dXVmczMTJOQkGCcTqcZNWqUWbx4sQkGg2HH6S9z9uCDD5oRI0aY6Ohoc9VVV5nbbrvNCi/G9Oz7y2GMMZGdswEAAOhdXAMDAABshwADAABshwADAABshwADAABshwADAABshwADAABshwADAABshwADAABshwADAABshwADAABshwADAABshwADAABs5/8DtjVNg64wcqoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length:  2711.2135593220337\n"
     ]
    }
   ],
   "source": [
    "# plot frames\n",
    "x= np.arange(0,len(all_frame_numbers))\n",
    "all_frame_numbers.sort()\n",
    "plt.scatter(x,all_frame_numbers)\n",
    "# plot horizontal line for minimum number of frames\n",
    "plt.axhline(minimum_frames, color='r')\n",
    "plt.show()\n",
    "mean_number_of_frames = np.mean(all_frame_numbers)\n",
    "print('Mean number of frames: ', mean_number_of_frames)\n",
    "\n",
    "\n",
    "# plot lengths\n",
    "x= np.arange(0,len(all_lengths))\n",
    "all_lengths.sort()\n",
    "plt.scatter(x,all_lengths)\n",
    "# plot horizontal line for minimum length\n",
    "plt.axhline(minimum_length, color='r')\n",
    "plt.show()\n",
    "mean_length = np.mean(all_lengths)\n",
    "print('Mean length: ', mean_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten arrays on the same frame size (C3 -> 27, L15 -> 15), save each frame in a separate file and transform data into h5-files\n",
    "\n",
    "transducer = transformation_transducer\n",
    "frame_length = transformation_frame_length\n",
    "number_of_frames = transformation_number_number_of_frames\n",
    "\n",
    "directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data_'+version\n",
    "new_directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Shortened_data_h5_'+str(frame_length)+'px_'+str(number_of_frames)+'frames_'+transducer+'_'+version\n",
    "# create new directory for shortened data\n",
    "if not os.path.exists(new_directory):\n",
    "    os.mkdir(new_directory)\n",
    "\n",
    "for dir in tqdm(os.listdir(directory)):\n",
    "    if os.path.isdir(directory+\"/\"+dir):\n",
    "        for file in os.listdir(directory+\"/\"+dir):\n",
    "            if transducer+'_large' in file and 'rf_no_tgc.npy' in file:\n",
    "                data = np.load(directory+\"/\"+dir+\"/\"+file)\n",
    "                # shorten data in axial depth\n",
    "                if len(data[0,:,0]) >= frame_length:\n",
    "                    shortened_data = data[:,:frame_length,:]\n",
    "\n",
    "                    # shorten data in frame length\n",
    "                    if len(data[0,0,:]) >= number_of_frames:\n",
    "                        shortened_data = shortened_data[:,:,:number_of_frames]\n",
    "                        for frame in range(0,len(shortened_data[0,0,:])):\n",
    "                            try: \n",
    "                                single_frame_array = shortened_data[:,:,frame]\n",
    "                            except:\n",
    "                                print('Error in file: '+file)\n",
    "                            with h5py.File(new_directory+'/'+dir+'_f'+f\"{frame:02d}\"+'_'+file[:(6+len(transducer))]+'.h5','w') as f:\n",
    "                                f.create_dataset('augmented',data=[False]*len(single_frame_array[:,0]))\n",
    "                                #f.create_dataset('coords',data=[[0,0]]*len(single_frame_array[:,0]))\n",
    "                                f.create_dataset('feats',data=single_frame_array)\n",
    "                            f.close()\n",
    "                    else:\n",
    "                        print('File '+dir+'/'+file+' has too few frames (only '+str(len(data[0,0,:]))+' frames)')\n",
    "                else:\n",
    "                    print('File '+dir+'/'+file+' is too short (only '+str(len(data[0,:,0]))+' pixels in axial direction)')\n",
    "    \n",
    "\n",
    "# create slide table with all patients and their corresponding frames\n",
    "slide_table_dict = {'Patient_ID': [], 'Frame_number': [], 'Filename': []}\n",
    "for file in os.listdir(new_directory):\n",
    "    slide_table_dict['Patient_ID'].append(file[:6])\n",
    "    slide_table_dict['Frame_number'].append(file[:7]+file[8:10])\n",
    "    slide_table_dict['Filename'].append(file[:-3])\n",
    "\n",
    "slide_table_df = pd.DataFrame(slide_table_dict)\n",
    "\n",
    "slide_table_df.to_csv('/Volumes/Extreme_SSD/Targets/slide_table_'+transducer+'_'+str(frame_length)+'px_'+str(number_of_frames)+'frames_'+version+'.csv', index=False)\n",
    "slide_table_df.to_excel('/Volumes/Extreme_SSD/Targets/slide_table_'+transducer+'_'+str(frame_length)+'px_'+str(number_of_frames)+'frames_'+version+'.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search specific recordings based on their array dimensions\n",
    "\n",
    "directory = 'Data/Finished_data'+version\n",
    "all_lengths = []\n",
    "\n",
    "for dir in os.listdir(directory):\n",
    "    if os.path.isdir(directory+\"/\"+dir):\n",
    "        for name in os.listdir(directory+\"/\"+dir):\n",
    "            if 'C3_large' in name and 'rf_no_tgc.npy' in name:\n",
    "                array = np.load(directory+\"/\"+dir+\"/\"+name)\n",
    "                one_length = len(array[0,:,0])\n",
    "                all_lengths.append(one_length)\n",
    "                if one_length > 3500:\n",
    "                    print(dir, one_length)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform shortened arrays with different numbers of frames to h5 files\n",
    "\n",
    "import h5py\n",
    "\n",
    "frame_length = transformation_frame_length\n",
    "transducer = transformation_transducer\n",
    "number_of_frames = transformation_number_number_of_frames\n",
    "\n",
    "directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Shortened_data_npy_'+str(frame_length)+'px_230224'\n",
    "#create new directory for h5 files\n",
    "if not os.path.exists('/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Shortened_data_h5_'+str(frame_length)+'px'+'_'+str(number_of_frames)+'frames_'+transducer+'_230224'):\n",
    "    os.makedirs()\n",
    "\n",
    "for file in tqdm(os.listdir(directory)):\n",
    "        # f = h5py.File('/Users/jakobschaefer/Downloads/jakob/Beispielvektor1.h5','r')\n",
    "\n",
    "        if file.startswith('.'):\n",
    "            os.remove(directory+'/'+file)\n",
    "        try:\n",
    "            np_array = np.load(directory+'/'+file)\n",
    "        except:\n",
    "            print(print(directory + \"/\" + file))\n",
    "\n",
    "        with h5py.File('/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Shortened_data_h5_'+str(frame_length)+'px_230224/'+file[:-3]+'h5', \"w\") as f:\n",
    "            dset = f.create_dataset(\"feats\", data = np_array, dtype='i')\n",
    "\n",
    "        f.close()\n",
    "\n",
    "\n",
    "        #f = h5py.File('/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Shortened_data_h5_230224/'+file[:-3]+'h5','r')\n",
    "        #print(f['array'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy files with and/or without tgc into new folder (for AI-implementation by Tim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6882e52062d4472a505019785804a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define start and end directory\n",
    "version = 'Vortraining_Tim'\n",
    "transducer = 'C3' # 'C3' or 'L15\n",
    "TGC = 'with_and_without_TGC' # 'with_TGC' or 'without_TGC' or 'with_and_without_TGC'\n",
    "\n",
    "start_directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Finished_data_'+version\n",
    "end_directory = '/Volumes/Extreme_SSD/Aufnahmen_vorverarbeitet/Exports_for_Tim/'+transducer+'_'+TGC+'_'+version\n",
    "\n",
    "# create new directory for data with and without TGC\n",
    "if not os.path.exists(end_directory):\n",
    "    os.mkdir(end_directory)\n",
    "\n",
    "# load arrays and copy them\n",
    "for dir in tqdm(os.listdir(start_directory)):\n",
    "    if dir.startswith('.'):\n",
    "        try:\n",
    "            os.rmdir(start_directory+'/'+dir)\n",
    "            os.remove(start_directory+'/'+dir)\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        for file in os.listdir(start_directory+'/'+dir):\n",
    "            if file.startswith('.'):\n",
    "                os.remove(start_directory+'/'+dir+'/'+file)\n",
    "            else:\n",
    "                if transducer in file and '_large' in file and 'rf_no_tgc.npy' in file:\n",
    "                    if TGC == 'with_and_without_TGC':\n",
    "                        shutil.copy(start_directory+'/'+dir+'/'+file, end_directory+'/'+dir+'_'+file[:-14]+'_rf_no_tgc.npy')\n",
    "                        shutil.copy(start_directory+'/'+dir+'/'+file[:-11]+'.npy', end_directory+'/'+dir+'_'+file[:-14]+'_rf.npy')\n",
    "                    if TGC == 'with_TGC':\n",
    "                        shutil.copy(start_directory+'/'+dir+'/'+file[:-11]+'.npy', end_directory+'/'+dir+'_'+file[:-14]+'_rf.npy')\n",
    "                    if TGC == 'without_TGC':\n",
    "                        shutil.copy(start_directory+'/'+dir+'/'+file, end_directory+'/'+dir+'_'+file[:-14]+'_rf_no_tgc.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save targets as csv\n",
    "# get results out of RedCap-Survey (csv)\n",
    "df = pd.read_csv(r'/Users/jakobschaefer/Documents/REDCap_Survey_'+version+'.csv')\n",
    "\n",
    "Patient_ID = df['patients_id'].tolist()\n",
    "Median_E = df['median_e'].tolist()\n",
    "IQR_E = df['iqr_e'].tolist()\n",
    "Median_CAP = df['median_cap'].tolist()\n",
    "IQR_CAP = df['iqr_cap'].tolist()\n",
    "\n",
    "target_dict = {'Patient_ID': Patient_ID, 'Median_E': Median_E, 'Median_CAP': Median_CAP} #, 'IQR_E': IQR_E, 'IQR_CAP': IQR_CAP\n",
    "# remove rows that contain NaN-values\n",
    "target_df = pd.DataFrame(target_dict).dropna() # remove lines without values\n",
    "\n",
    "# check if there are any recordings without results or results without recordings\n",
    "for file in os.listdir(end_directory):\n",
    "    if not file[:6] in target_df['Patient_ID'].tolist() and not file[:9] in target_df['Patient_ID'].tolist():\n",
    "        \n",
    "        print(file[:file.find('_')]+' has no results')\n",
    "\n",
    "# safe target_dict as csv\n",
    "target_df.to_csv('/Volumes/Extreme_SSD/Targets/targets_'+transducer+'_'+version+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RF-Interpreter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "437b0f63b0d450468eb9a3658f2b10f70ea508fb99807e0899da98fa57e06dd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
